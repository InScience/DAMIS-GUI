INSERT INTO `cluster` (`ClusterName`, `ClusterWorkloadHost`, `ClusterDescription`, `ClusterID`, `ClusterUrl`, `WorkloadUrl`) VALUES
('MII Cluster', 'test', 'Distributed Computing cluster of Vilnius University Institute of Mathematics and Informatics', 1, 'http://cluster.mii.lt/', 'http://cluster.mii.lt/ganglia/'),
('MIF VU SK2', 'test', 'Supercomputer of Vilnius University Faculty of Mathematics and Informatics', 2,'http://mif.vu.lt/cluster/', 'http://k007.mif.vu.lt/ganglia2/');

INSERT INTO `componenttype` (`ComponentType`, `ComponentTypeID`) VALUES
('Upload data', 1),
('Preprocessing', 2),
('Statistical primitives', 3),
('Dimensionality reduction', 4),
('Classification, clustering', 5),
('View results', 6);

INSERT INTO `parameterconnectiontype` (`ParameterConnectionType`, `ParameterConnectionTypeID`) VALUES
('INPUT_CONNECTION', 1),
('OUTPUT_CONNECTION', 2),
('INPUT_VALUE', 3);

INSERT INTO `component` (`ComponentName`, `ComponentIcon`, `ComponentWSDLRunHost`, `ComponentWSDLCallFunction`,
`ComponentDescription`, `ComponentAltDescription`, `ComponentLabelLT`, `ComponentLabelEN`, `ComponentID`, `ClusterID`,
`ComponentTypeID`, `FormType`) VALUES
('Upload new file', 'upload-file-ico-1.jpeg', NULL, 'UPLOAD FILE', 'Upload file for data analysis', NULL, NULL, NULL, 1, 'NewFile', 1, 1),
('Upload new file', 'upload-file-ico-1.jpeg', NULL, 'UPLOAD FILE', 'Upload file for data analysis', NULL, NULL, NULL, 2, 'NewFile', 2, 1),
('Choose uploaded file', 'existing-file-ico.jpeg', NULL, 'EXISTING FILE', 'Select uploaded file', NULL, NULL, NULL, 3, 'UploadedFile', 1, 1),
('Choose uploaded file', 'existing-file-ico.jpeg', NULL, 'EXISTING FILE', 'Select uploaded file', NULL, NULL, NULL, 4, 'UploadedFile', 2, 1),
('Upload file from MIDAS', 'midas-file.jpeg', NULL, 'MIDAS FILE', 'Select file from MIDAS archive', NULL, NULL, NULL, 5, 'NoForm', 1, 1),
('Upload file from MIDAS', 'midas-file.jpeg', NULL, 'MIDAS FILE', 'Select file from MIDAS archive', NULL, NULL, NULL, 6, 'NoForm', 2, 1),
('Clean data', 'clean-data-ico.jpeg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'CLEANDATA', 'Data cleaning', NULL, NULL, NULL, 7, 'NoForm', 1, 2),
('Clean data', 'clean-data-ico.jpeg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'CLEANDATA', 'Data cleaning', NULL, NULL, NULL, 8, 'NoForm', 2, 2),
('Filter data', 'filter-data-ico.jpeg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'FILTERDATA', 'Filter data', NULL, NULL, NULL, 9, 'Filter', 1, 2),
('Filter data', 'filter-data-ico.jpeg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'FILTERDATA', 'Filter data', NULL, NULL, NULL, 10, 'Filter', 2, 2),
('Split data', 'split-data-ico.jpeg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'SPLITDATA', 'Split a file into given number of parts', NULL, NULL, NULL, 11, 'SplitData', 1, 2),
('Split data', 'split-data-ico.jpeg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'SPLITDATA', 'Split a file into given number of parts',	 NULL, NULL, NULL, 12, 'SplitData', 2, 2),
('Transpose data', 'transpose-data-ico.jpeg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'TRANSPOSEDATA', 'Transpose (rotate) data from rows to columns or vice versa', NULL, NULL, NULL, 13, 'NoForm', 1, 2),
('Transpose data', 'transpose-data-ico.jpeg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'TRANSPOSEDATA', 'Transpose (rotate) data from rows to columns or vice versa', NULL, NULL, NULL, 14, 'NoForm', 2, 2),
('Norm data', 'transform-data-ico.jpeg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'NORMDATA', 'Data transformation', NULL, NULL, NULL, 15, 'NormData', 1, 2),
('Norm data', 'transform-data-ico.jpeg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'NORMDATA', 'Data transformation', NULL, NULL, NULL, 16, 'NormData', 2, 2),
('Feature selection', 'select-ico.jpeg', NULL, 'SELECT', 'Select features', NULL, NULL, NULL, 17, 'Select', 1, 2),
('Feature selection', 'select-ico.jpeg', NULL, 'SELECT', 'Select features', NULL, NULL, NULL, 18, 'Select', 2, 2),
('Statistical data', 'statistical-primitives-icon.jpeg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'STATPRIMITIVES', 'The set of statistical primitives', NULL, NULL, NULL, 19, 'NoForm', 1, 3),
('Statistical data', 'statistical-primitives-icon.jpeg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'STATPRIMITIVES', 'The set of statistical primitives', NULL, NULL, NULL, 20, 'NoForm', 2, 3),
('PCA', 'dimensionality-reduction-ico.jpg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'PCA', 'Principal Component Analysis', NULL, NULL, NULL, 21, 'Pca', 1, 4),
('PCA', 'dimensionality-reduction-ico.jpg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'PCA', 'Principal Component Analysis', NULL, NULL, NULL, 22, 'Pca', 2, 4),
('SMACOF (MDS)', 'dimensionality-reduction-ico.jpg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'SMACOFMDS', 'SMACOF (MDS) algorithm', NULL, NULL, NULL, 23, 'Smacof', 1, 4),
('SMACOF (MDS)', 'dimensionality-reduction-ico.jpg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'SMACOFMDS', 'SMACOF (MDS) algorithm', NULL, NULL, NULL, 24, 'Smacof', 2, 4),
('DMA', 'dimensionality-reduction-ico.jpg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'DMA', 'Diagonal majorization algorithm', NULL, NULL, NULL, 25, 'Dma', 1, 4),
('DMA', 'dimensionality-reduction-ico.jpg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'DMA', 'Diagonal majorization algorithm', NULL, NULL, NULL, 26, 'Dma', 2, 4),
('Relative MDS', 'dimensionality-reduction-ico.jpg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'RELMDS', 'Relative Multidimensional Scaling (MDS)  algorithm', NULL, NULL, NULL, 27, 'RelativeMds', 1, 4),
('Relative MDS', 'dimensionality-reduction-ico.jpg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'RELMDS', 'Relative Multidimensional Scaling (MDS)  algorithm', NULL, NULL, NULL, 28, 'RelativeMds', 2, 4),
('SAMANN', 'dimensionality-reduction-ico.jpg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'SAMANN', 'SAMANN algorithm', NULL, NULL, NULL, 29, 'Samann', 1, 4),
('SAMANN', 'dimensionality-reduction-ico.jpg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'SAMANN', 'SAMANN algorithm', NULL, NULL, NULL, 30, 'Samann', 2, 4),
('SOM-MDS', 'dimensionality-reduction-ico.jpg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'SOMMDS', 'SOM for Multidimensional Data Visualization', NULL, NULL, NULL, 31, 'SomMds', 1, 4),
('SOM-MDS', 'dimensionality-reduction-ico.jpg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'SOMMDS', '', NULL, NULL, NULL, 32, 'SomMds', 2, 4),
('SOM', 'som-ico.jpeg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'SOM', 'Self-Organizing Map (SOM)', NULL, NULL, NULL, 33, 'Som', 1, 5),
('SOM', 'som-ico.jpeg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'SOM', 'Self-Organizing Map (SOM)', NULL, NULL, NULL, 34, 'Som', 2, 5),
('MLP', 'mlp-ico.jpeg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'MLP', 'Multilayer perceptron', NULL, NULL, NULL, 35, 'Mlp', 1, 5),
('MLP', 'mlp-ico.jpeg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'MLP', 'Multilayer perceptron', NULL, NULL, NULL, 36, 'Mlp', 2, 5),
('C 4.5', 'C45-ico.jpeg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'C45', 'C4.5 classifier', NULL, NULL, NULL, 37, 'C45', 1, 5),
('C 4.5', 'C45-ico.jpeg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'C45', 'C4.5 classifier', NULL, NULL, NULL, 38, 'C45', 2, 5),
('K-MEANS', 'kmeans-ico.jpeg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'KMEANS', 'k-means clustering', NULL, NULL, NULL, 39, 'Kmeans', 1, 5),
('K-MEANS', 'kmeans-ico.jpeg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'KMEANS', 'k-means clustering', NULL, NULL, NULL, 40, 'Kmeans', 2, 5),
('Technical details', 'technical-details-ico.jpeg', NULL, 'TECHNICALINFO', 'Show all component''s outputs'' values', NULL, NULL, NULL, 41, 'TechnicalInfo', 1, 6),
('Technical details', 'technical-details-ico.jpeg', NULL, 'TECHNICALINFO', 'Show all component''s outputs'' values', NULL, NULL, NULL, 42, 'TechnicalInfo', 2, 6),
('Matrix view', 'matrix-view-ico.jpeg', NULL, 'MATRIX', 'Results matrix view', NULL, NULL, NULL, 43, 'Matrix', 1, 6),
('Matrix view', 'matrix-view-ico.jpeg', NULL, 'MATRIX', 'Results matrix view', NULL, NULL, NULL, 44, 'Matrix', 2, 6),
('Chart view', 'chart-ico.jpeg', NULL, 'CHART', 'Chart', NULL, NULL, NULL, 45, 'Chart', 1, 6),
('Chart view', 'chart-ico.jpeg', NULL, 'CHART', 'Chart', NULL, NULL, NULL, 46, 'Chart', 2, 6);


INSERT INTO `parameter` (`ParameterName`, `ParameterIsRequired`, `ParameterDefault`, `ParameterDescription`,
                         `ParameterLabelLT`, `ParameterLabelEN`, `ParameterID`, `ParameterTypeID`,
                         `ParameterConnectionTypeID`, `ComponentID`, `ParameterSlug`, `ParameterPosition`) VALUES
('dataset', 0, NULL, NULL, NULL, NULL, 1, NULL, 2, 1, 'Y', NULL),
('dataset', 0, NULL, NULL, NULL, NULL, 2, NULL, 2, 2, 'Y', NULL),
('X', 0, NULL, NULL, NULL, NULL, 3, NULL, 1, 9, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 4, NULL, 2, 9, 'Y', NULL),
('X', 0, NULL, NULL, NULL, NULL, 5, NULL, 1, 10, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 6, NULL, 2, 10, 'Y', NULL),
('Result type', 1, NULL, NULL, NULL, NULL, 9, NULL, 3, 9, 'retFilteredData', 1),
('Z value', 1, NULL, NULL, NULL, NULL, 10, NULL, 3, 9, 'zValue', 2),
('Attribute', 1, NULL, NULL, NULL, NULL, 11, NULL, 3, 9, 'attrIndex', 3),
('Result type', 1, NULL, NULL, NULL, NULL, 12, NULL, 3, 10, 'retFilteredData', 1),
('Z value', 1, NULL, NULL, NULL, NULL, 13, NULL, 3, 10, 'zValue', 2),
('Attribute', 1, NULL, NULL, NULL, NULL, 14, NULL, 3, 10, 'attrIndex', 3),
('Maximum number of iteartion', 1, NULL, NULL, NULL, NULL, 15, NULL, 3, 35, 'maxIteration', 7),
('1st layer', 1, NULL, NULL, NULL, NULL, 16, NULL, 3, 35, 'h1pNo', 1),
('2nd layer', 1, NULL, NULL, NULL, NULL, 17, NULL, 3, 35, 'h2pNo', 2),
('3rd layer', 1, NULL, NULL, NULL, NULL, 18, NULL, 3, 35, 'h3pNo', 3),
('Size of training data', 1, NULL, NULL, NULL, NULL, 19, NULL, 3, 35, 'dL', 4),
('Size of test data', 1, NULL, NULL, NULL, NULL, 20, NULL, 3, 35, 'dT', 5),
('Size of validation data', 1, NULL, NULL, NULL, NULL, 21, NULL, 3, 35, 'dV', 6),
('X', 0, NULL, NULL, NULL, NULL, 22, NULL, 1, 35, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 23, NULL, 2, 35, 'Y', NULL),
('Maximum number of iteartion', 1, NULL, NULL, NULL, NULL, 24, NULL, 3, 36, 'maxIteration', 7),
('1st layer', 1, NULL, NULL, NULL, NULL, 25, NULL, 3, 36, 'h1pNo', 1),
('2nd layer', 1, NULL, NULL, NULL, NULL, 26, NULL, 3, 36, 'h2pNo', 2),
('3rd layer', 1, NULL, NULL, NULL, NULL, 27, NULL, 3, 36, 'h3pNo', 3),
('Size of training data', 1, NULL, NULL, NULL, NULL, 28, NULL, 3, 36, 'dL', 4),
('Size of test data', 1, NULL, NULL, NULL, NULL, 29, NULL, 3, 36, 'dT', 5),
('Size of validation data', 1, NULL, NULL, NULL, NULL, 30, NULL, 3, 36, 'dV', 6),
('X', 0, NULL, NULL, NULL, NULL, 31, NULL, 1, 36, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 32, NULL, 2, 36, 'Y', NULL),
('dataset', 0, NULL, NULL, NULL, NULL, 33, NULL, 2, 5, 'Y', NULL),
('dataset', 0, NULL, NULL, NULL, NULL, 34, NULL, 2, 6, 'Y', NULL),
('Number of rows of SOM', 1, NULL, NULL, NULL, NULL, 35, NULL, 3, 31, 'rows', 1),
('Number of columns of SOM', 1, NULL, NULL, NULL, NULL, 36, NULL, 3, 31, 'columns', 2),
('Number of SOM training epochs', 1, NULL, NULL, NULL, NULL, 37, NULL, 3, 31, 'eHat', 3),
('Projection space of MDS', 1, NULL, NULL, NULL, NULL, 38, NULL, 3, 31, 'mdsProjection', 6),
('Number of iterations of MDS', 1, NULL, NULL, NULL, NULL, 39, NULL, 3, 31, 'mdsIteration', 4),
('Minimal stress change', 1, NULL, NULL, NULL, NULL, 40, NULL, 3, 31, 'eps', 5),
('Number of rows of SOM', 1, NULL, NULL, NULL, NULL, 41, NULL, 3, 32, 'rows', 1),
('Number of columns of SOM', 1, NULL, NULL, NULL, NULL, 42, NULL, 3, 32, 'columns', 2),
('Number of SOM training epochs', 1, NULL, NULL, NULL, NULL, 43, NULL, 3, 32, 'eHat', 3),
('Projection space of MDS', 1, NULL, NULL, NULL, NULL, 44, NULL, 3, 32, 'mdsProjection', 6),
('Number of iterations of MDS', 1, NULL, NULL, NULL, NULL, 45, NULL, 3, 32, 'mdsIteration', 4),
('Minimal stress change', 1, NULL, NULL, NULL, NULL, 46, NULL, 3, 32, 'eps', 5),
('X', 0, NULL, NULL, NULL, NULL, 47, NULL, 1, 31, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 48, NULL, 2, 31, 'Y', NULL),
('X', 0, NULL, NULL, NULL, NULL, 49, NULL, 1, 32, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 50, NULL, 2, 32, 'Y', NULL),
('X', 0, NULL, NULL, NULL, NULL, 51, NULL, 1, 27, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 52, NULL, 2, 27, 'Y', NULL),
('X', 0, NULL, NULL, NULL, NULL, 53, NULL, 1, 28, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 54, NULL, 2, 28, 'Y', NULL),
('Projection space', 1, NULL, NULL, NULL, NULL, 55, NULL, 3, 27, 'd', 1),
('Maximum number of iteration', 1, NULL, NULL, NULL, NULL, 56, NULL, 3, 27, 'maxIteration', 2),
('Minimal stress change', 1, NULL, NULL, NULL, NULL, 57, NULL, 3, 27, 'eps', 3),
('Relative number of basis objects', 1, NULL, NULL, NULL, NULL, 58, NULL, 3, 27, 'noOfBaseVectors', 4),
('Select Basis objects strategy', 1, NULL, NULL, NULL, NULL, 59, NULL, 3, 27, 'selStrategy', 5),
('Projection space', 1, NULL, NULL, NULL, NULL, 60, NULL, 3, 28, 'd', 1),
('Maximum number of iteration', 1, NULL, NULL, NULL, NULL, 61, NULL, 3, 28, 'maxIteration', 2),
('Minimal stress change', 1, NULL, NULL, NULL, NULL, 62, NULL, 3, 28, 'eps', 3),
('Relative number of basis objects', 1, NULL, NULL, NULL, NULL, 63, NULL, 3, 28, 'noOfBaseVectors', 4),
('Select Basis objects strategy', 1, NULL, NULL, NULL, NULL, 64, NULL, 3, 28, 'selStrategy', 5),
('X', 0, NULL, NULL, NULL, NULL, 65, NULL, 1, 7, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 66, NULL, 2, 7, 'Y', NULL),
('X', 0, NULL, NULL, NULL, NULL, 67, NULL, 1, 8, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 68, NULL, 2, 8, 'Y', NULL),
('X', 0, NULL, NULL, NULL, NULL, 69, NULL, 1, 45, 'X', NULL),
('X', 0, NULL, NULL, NULL, NULL, 70, NULL, 1, 46, 'X', NULL),
('dataset', 0, NULL, NULL, NULL, NULL, 71, NULL, 2, 3, 'Y', NULL),
('dataset', 0, NULL, NULL, NULL, NULL, 72, NULL, 2, 4, 'Y', NULL),
('X', 0, NULL, NULL, NULL, NULL, 73, NULL, 1, 21, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 74, NULL, 2, 21, 'Y', NULL),
('X', 0, NULL, NULL, NULL, NULL, 75, NULL, 1, 22, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 76, NULL, 2, 22, 'Y', NULL),
('Choose PCA projection', 1, NULL, NULL, NULL, NULL, 77, NULL, 3, 21, 'projType', 1),
('Space/Variance', 1, NULL, NULL, NULL, NULL, 78, NULL, 3, 21, 'd', 2),
('Choose PCA projection', 1, NULL, NULL, NULL, NULL, 79, NULL, 3, 22, 'projType', 1),
('Space/Variance', 1, NULL, NULL, NULL, NULL, 80, NULL, 3, 22, 'd', 2),
('X', 0, NULL, NULL, NULL, NULL, 81, NULL, 1, 25, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 82, NULL, 2, 25, 'Y', NULL),
('X', 0, NULL, NULL, NULL, NULL, 83, NULL, 1, 26, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 84, NULL, 2, 26, 'Y', NULL),
('Projection space', 1, NULL, NULL, NULL, NULL, 85, NULL, 3, 25, 'd', 1),
('Maximum number of iteration', 1, NULL, NULL, NULL, NULL, 86, NULL, 3, 25, 'maxIteration', 2),
('Minimal stress change', 1, NULL, NULL, NULL, NULL, 87, NULL, 3, 25, 'eps', 3),
('Relative number of neighbours', 1, NULL, NULL, NULL, NULL, 88, NULL, 3, 25, 'neighbour', 4),
('Projection space', 1, NULL, NULL, NULL, NULL, 89, NULL, 3, 26, 'd', 1),
('Maximum number of iteration', 1, NULL, NULL, NULL, NULL, 90, NULL, 3, 26, 'maxIteration', 2),
('Minimal stress change', 1, NULL, NULL, NULL, NULL, 91, NULL, 3, 26, 'eps', 3),
('Relative number of neighbours', 1, NULL, NULL, NULL, NULL, 92, NULL, 3, 26, 'neighbour', 4),
('X', 0, NULL, NULL, NULL, NULL, 93, NULL, 1, 39, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 94, NULL, 2, 39, 'Y', NULL),
('X', 0, NULL, NULL, NULL, NULL, 95, NULL, 1, 40, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 96, NULL, 2, 40, 'Y', NULL),
('Maximum number of cluster', 1, NULL, NULL, NULL, NULL, 97, NULL, 3, 39, 'kMax', 1),
('Maximum number of iteration', 1, NULL, NULL, NULL, NULL, 98, NULL, 3, 39, 'maxIteration', 2),
('Maximum number of cluster', 1, NULL, NULL, NULL, NULL, 99, NULL, 3, 40, 'kMax', 1),
('Maximum number of iteration', 1, NULL, NULL, NULL, NULL, 100, NULL, 3, 40, 'maxIteration', 2),
('X', 0, NULL, NULL, NULL, NULL, 101, NULL, 1, 13, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 102, NULL, 2, 13, 'Y', NULL),
('X', 0, NULL, NULL, NULL, NULL, 103, NULL, 1, 14, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 104, NULL, 2, 14, 'Y', NULL),
('X', 0, NULL, NULL, NULL, NULL, 105, NULL, 1, 11, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 106, NULL, 2, 11, 'Y', NULL),
('X', 0, NULL, NULL, NULL, NULL, 107, NULL, 1, 12, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 108, NULL, 2, 12, 'Y', NULL),
('Choose object sort type', 1, NULL, NULL, NULL, NULL, 109, NULL, 3, 11, 'reshufleObjects', 1),
('First subset size', 1, NULL, NULL, NULL, NULL, 110, NULL, 3, 11, 'firstSubsetPerc', 2),
('Second subset size', 1, NULL, NULL, NULL, NULL, 111, NULL, 3, 11, 'secondSubsetPerc', 3),
('Choose object sort type', 1, NULL, NULL, NULL, NULL, 112, NULL, 3, 12, 'reshufleObjects', 1),
('First subset size', 1, NULL, NULL, NULL, NULL, 113, NULL, 3, 12, 'firstSubsetPerc', 2),
('Second subset size', 1, NULL, NULL, NULL, NULL, 114, NULL, 3, 12, 'secondSubsetPerc', 3),
('X', 0, NULL, NULL, NULL, NULL, 115, NULL, 1, 19, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 116, NULL, 2, 19, 'Y', NULL),
('X', 0, NULL, NULL, NULL, NULL, 117, NULL, 1, 20, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 118, NULL, 2, 20, 'Y', NULL),
('X', 0, NULL, NULL, NULL, NULL, 119, NULL, 1, 15, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 120, NULL, 2, 15, 'Y', NULL),
('X', 0, NULL, NULL, NULL, NULL, 121, NULL, 1, 16, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 122, NULL, 2, 16, 'Y', NULL),
('Choose norm method', 1, NULL, NULL, NULL, NULL, 123, NULL, 3, 15, 'normMeanStd', 1),
('a', 1, NULL, NULL, NULL, NULL, 124, NULL, 3, 15, 'a', 2),
('b', 1, NULL, NULL, NULL, NULL, 125, NULL, 3, 15, 'b', 3),
('Choose norm method', 1, NULL, NULL, NULL, NULL, 126, NULL, 3, 16, 'normMeanStd', 1),
('a', 1, NULL, NULL, NULL, NULL, 127, NULL, 3, 16, 'a', 2),
('b', 1, NULL, NULL, NULL, NULL, 128, NULL, 3, 16, 'b', 3),
('X', 0, NULL, NULL, NULL, NULL, 129, NULL, 1, 23, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 130, NULL, 2, 23, 'Y', NULL),
('X', 0, NULL, NULL, NULL, NULL, 131, NULL, 1, 24, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 132, NULL, 2, 24, 'Y', NULL),
('Projection space', 1, NULL, NULL, NULL, NULL, 133, NULL, 3, 23, 'd', 1),
('Maximum number of iteration', 1, NULL, NULL, NULL, NULL, 134, NULL, 3, 23, 'maxIteration', 2),
('Minimal stress change', 1, NULL, NULL, NULL, NULL, 135, NULL, 3, 23, 'eps', 3),
('Does apply Seidel modification?', 1, NULL, NULL, NULL, NULL, 136, NULL, 3, 23, 'zeidel', 4),
('Projection space', 1, NULL, NULL, NULL, NULL, 137, NULL, 3, 24, 'd', 1),
('Maximum number of iteration', 1, NULL, NULL, NULL, NULL, 138, NULL, 3, 24, 'maxIteration', 2),
('Minimal stress change', 1, NULL, NULL, NULL, NULL, 139, NULL, 3, 24, 'eps', 3),
('Does apply Seidel modification?', 1, NULL, NULL, NULL, NULL, 140, NULL, 3, 24, 'zeidel', 4),
('X', 0, NULL, NULL, NULL, NULL, 141, NULL, 1, 29, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 142, NULL, 2, 29, 'Y', NULL),
('X', 0, NULL, NULL, NULL, NULL, 143, NULL, 1, 30, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 144, NULL, 2, 30, 'Y', NULL),
('Projection space', 1, NULL, NULL, NULL, NULL, 145, NULL, 3, 29, 'd', 1),
('Maximum number of iteration', 1, NULL, NULL, NULL, NULL, 146, NULL, 3, 29, 'maxIteration', 2),
('Relative size of the training data', 1, NULL, NULL, NULL, NULL, 147, NULL, 3, 29, 'mTrain', 3),
('Number of neurons in the hidden layer', 1, NULL, NULL, NULL, NULL, 148, NULL, 3, 29, 'nNeurons', 4),
('Value of the learning rate', 1, NULL, NULL, NULL, NULL, 149, NULL, 3, 29, 'eta', 5),
('Projection space', 1, NULL, NULL, NULL, NULL, 150, NULL, 3, 30, 'd', 1),
('Maximum number of iteration', 1, NULL, NULL, NULL, NULL, 151, NULL, 3, 30, 'maxIteration', 2),
('Relative size of the training data', 1, NULL, NULL, NULL, NULL, 152, NULL, 3, 30, 'mTrain', 3),
('Number of neurons in the hidden layer', 1, NULL, NULL, NULL, NULL, 153, NULL, 3, 30, 'nNeurons', 4),
('Value of the learning rate', 1, NULL, NULL, NULL, NULL, 154, NULL, 3, 30, 'eta', 5),
('X', 0, NULL, NULL, NULL, NULL, 155, NULL, 1, 33, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 156, NULL, 2, 33, 'Y', NULL),
('X', 0, NULL, NULL, NULL, NULL, 157, NULL, 1, 34, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 158, NULL, 2, 34, 'Y', NULL),
('Number of rows', 1, NULL, NULL, NULL, NULL, 159, NULL, 3, 33, 'rows', 1),
('Number of columns', 1, NULL, NULL, NULL, NULL, 160, NULL, 3, 33, 'columns', 2),
('Number of training epochs', 1, NULL, NULL, NULL, NULL, 161, NULL, 3, 33, 'eHat', 3),
('Number of rows', 1, NULL, NULL, NULL, NULL, 162, NULL, 3, 34, 'rows', 1),
('Number of columns', 1, NULL, NULL, NULL, NULL, 163, NULL, 3, 34, 'columns', 2),
('Number of training epochs', 1, NULL, NULL, NULL, NULL, 164, NULL, 3, 34, 'eHat', 3),
('X', 0, NULL, NULL, NULL, NULL, 165, NULL, 1, 37, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 166, NULL, 2, 37, 'Y', NULL),
('X', 0, NULL, NULL, NULL, NULL, 167, NULL, 1, 38, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 168, NULL, 2, 38, 'Y', NULL),
('Confidence level', 1, NULL, NULL, NULL, NULL, 169, NULL, 3, 37, 'q', 1),
('Size of training data', 1, NULL, NULL, NULL, NULL, 170, NULL, 3, 37, 'dL', 2),
('Size of test data', 1, NULL, NULL, NULL, NULL, 171, NULL, 3, 37, 'dT', 3),
('Confidence level', 1, NULL, NULL, NULL, NULL, 172, NULL, 3, 38, 'q', 1),
('Size of training data', 1, NULL, NULL, NULL, NULL, 173, NULL, 3, 38, 'dL', 2),
('Size of test data', 1, NULL, NULL, NULL, NULL, 174, NULL, 3, 38, 'dT', 3),
('X', 0, NULL, NULL, NULL, NULL, 175, NULL, 1, 43, 'X', NULL),
('X', 0, NULL, NULL, NULL, NULL, 176, NULL, 1, 44, 'X', NULL),
('X', 0, NULL, NULL, NULL, NULL, 177, NULL, 1, 41, 'X', NULL),
('X', 0, NULL, NULL, NULL, NULL, 178, NULL, 1, 42, 'X', NULL),
('X', 0, NULL, NULL, NULL, NULL, 179, NULL, 1, 17, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 180, NULL, 2, 17, 'Y', NULL),
('X', 0, NULL, NULL, NULL, NULL, 181, NULL, 1, 18, 'X', NULL),
('Y', 0, NULL, NULL, NULL, NULL, 182, NULL, 2, 18, 'Y', NULL),
('Attributes', 1, NULL, NULL, NULL, NULL, 183, NULL, 3, 17, 'attr', 1),
('Selected attributes', 1, NULL, NULL, NULL, NULL, 184, NULL, 3, 17, 'selAttr', 2),
('Class attribute', 1, NULL, NULL, NULL, NULL, 185, NULL, 3, 17, 'classAttr', 3),
('Attributes', 1, NULL, NULL, NULL, NULL, 186, NULL, 3, 18, 'attr', 1),
('Selected attributes', 1, NULL, NULL, NULL, NULL, 187, NULL, 3, 18, 'selAttr', 2),
('Class attribute', 1, NULL, NULL, NULL, NULL, 188, NULL, 3, 18, 'classAttr', 3),
('Yalt', 0, NULL, NULL, NULL, NULL, 189, NULL, 2, 11, 'Yalt', NULL),
('Yalt', 0, NULL, NULL, NULL, NULL, 190, NULL, 2, 12, 'Yalt', NULL);


INSERT INTO `experimentstatus` (`ExperimentStatus`, `ExperimentStatusID`) VALUES
	('SAVED', 1),
	('EXECUTING', 2),
	('FINISHED', 3),
	('ERROR', 4);

-- --------------------------------------------------------
-- help pages
-- --------------------------------------------------------

INSERT INTO `page` (`id`, `title`, `slug`, `text`, `position`, `groupName`, `created`, `updated`, `language`) VALUES
    (1, 'Help', 'help', 'help', '<h2>Uploading of data</h2>\r\n<h3>Upload file</h3>\r\n<p>Upload data file. It is possible to upload data table from a supported file formats: tab, txt, csv, ARFF and XML files, which are compressed in zip format.</p>\r\n<p>Requirements for data file: A dataset is roughly equivalent to a two-dimensional spreadsheet or database table. A dataset is a collection of instances, where each instance consists of a number of attributes. The external representation of an Instances class is an ARFF file, which consists of a header describing the attribute types and the data as comma-separated list.</p>\r\n<h3>Existing file</h3>\r\n<p>Open a set of instances from DAMIS data base.</p>\r\n<h3>MIDAS file</h3>\r\n<p>Open a set of instances from MIDAS data base</p>\r\n<h2>Preprocessing</h2>\r\n<h3>Cleaning | Cleaning data</h3>\r\n<p>Cleaning data reduces errors and improves the data quality for further data analysis. After reading the ARFF file, data section checking is initiated. Each data section attribute is checked whether its data type conforms the type declared in attribute section if not then error message is sent to the user. Also it is checked the missing data. At the moment if missing object data is found, then this object will be eliminated from the further calculations. In this way it isensured that all data records will have values and are suitable for further analysis.</p>\r\n<h4><strong>Parameters:</strong></h4>\r\n<p>This component does not have control parameters.</p>\r\n<h3>Filtering | Filter data</h3>\r\n<p>Filtering removes instances from dataset that meet a particular criterion. These instances are called outliers, i.e.the data instances which are significantly different from the remaining data. Result of filtering should be either the analyzed data set without outliers, or only outliers. Filtering is performed according to a selected attribute and the threshold of Z value (quintile). It is recommended to use Z value greater than 3.0.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<ul>\r\n<li><strong>Choose filtering results</strong> – without outliers, only outliers.</li>\r\n<li><strong>Z value – </strong>valid Z value is positive real number.</li>\r\n<li><strong>Attribute</strong> – set the selected attribute for outlier filtering</li>\r\n</ul>\r\n<h3>Split data | Splitting of initial data set into two smaller subsets</h3>\r\n<p>Split data – splitting of initial data set into two smaller subsets. Two obtained subsets could be analysed by parallel or analysed one of them, for example, subset of instances could be represented regularities of all population.</p>\r\n<p>Splitting ways of the initial data set:</p>\r\n<ol>\r\n<li>Order of initial data instances is unchanged and splitting of initial data set into two smaller subsets is done according to values of splitting parameters.</li>\r\n<li>Instances of initial data set are mixed at random and splitting of initial data set into two smaller subsets is done according to values of splitting parameters.</li>\r\n</ol>\r\n<p><strong>Parameters:</strong></p>\r\n<ul>\r\n<li><strong><strong>Choose object sort type<strong> – Order left intact</strong></strong></strong> (Order of initial data instances is unchanged);<strong><strong> Random </strong></strong>(Instances of initial data set are mixed at random).</li>\r\n<li>\r\n<p><strong>First subset size<strong> –</strong></strong> Sets the relative (percentage) size of the first subset from the initial data set.</p>\r\n</li>\r\n<li>\r\n<p><strong>Second subset size<strong> –</strong></strong> Size of second subset is calculated automatically by formula (100 %- First subset size).</p>\r\n</li>\r\n</ul>\r\n<h3>Transpose data</h3>\r\n<p>Transpose (rotate) data from rows to columns or vice versa.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<p>This component does not have control parameters.<br /><br /></p>\r\n<h3>Norm data | Data Transformation by Normalization</h3>\r\n<p>The measurement unit used can affect the data analysis. To help avoid dependence on the choice of measurement units, the data should be normalized or standardized. This involves transforming the data to fall within a smaller or common range. Normalizing the data attempts to give all attributes an equal weight. Two methods for data normalization could be used:</p>\r\n<ol>\r\n<li>The values for an each attribute are normalized based on the mean (i.e., average) and standard deviation. Default values: means equal 0, standard deviation equal 1.</li>\r\n<li>Min-max normalization performs a linear transformation on the original data. Min-max normalization maps a original value of each attribute to a new value in the interval [a, b].</li>\r\n</ol>\r\n<p><strong>Parameters:</strong></p>\r\n<ul>\r\n<li><strong>Mean a, standard deviation b </strong>– the values for an each attribute are normalized based on the mean (i.e., average) (parameter a) and standard deviation (parameter b). Default values: mean a=0, standard deviation b=1.</li>\r\n<li><strong>Interval [a; b] – </strong>Min-max normalization maps a original value of each attribute to a new value in the interval [a, b]. Default values: a=0, b=1, interval upper bound must be greater than lower.</li>\r\n</ul>\r\n<h3>Feature selection</h3>\r\n<p>Feature selection component is used to manually compose new analyzed data domain. It is possible to decide which attributes will be used and how. For instance, for building a classification model, the domain would be composed of a set of attributes and a class attribute, which is also selected from a set of attributes. The attributes are included in the data set but are, for most of the methods, not considered in data analysis.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<ul>\r\n<li><strong>Selected attributes – </strong><strong>selected data attributes in the new data file. </strong>Default value – empty list.</li>\r\n<li><strong>Class attribute<strong> - </strong></strong>A class attribute is selected from all attributes list of initial data set. Default value – empty or none. If none, the new data set will be classless.</li>\r\n</ul>\r\n<h2>Statistical primitives</h2>\r\n<h3>Statistical data| Calculation of statistical primitives</h3>\r\n<p>Calculation of statistical primitives: min, max, mean, standard deviation, median.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<p>This component does not have control parameters.</p>\r\n<h2>Dimension reduction</h2>\r\n<h3>PCA – principal component analysis</h3>\r\n<p>PCA is a standard technique for visualizing high dimensional data and for data pre-processing. PCA reduces the dimensionality (the number of variables) of a data set by maintaining as much variance as possible.</p>\r\n<p>Principal component analysis (PCA) rotates the original data space such that the axes of the new coordinate system point into the directions of highest variance of the data. The axes or new variables are termed principal components (PCs) and are ordered by variance: The first component represents the direction of the highest variance of the data. The direction of the second component represents the highest of the remaining variance orthogonal to the first component. This can be naturally extended to obtain the required number of components which together span a component space covering the desired amount of variance. Since components describe specific directions in the data space, each component depends by certain amounts on each of the original variables: Each component is a linear combination of all original variables.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<ul>\r\n<li><strong>Space</strong> – low-dimensional space or projection space; positive integer value, space dimension cannot be greater than quantity of attributes in analysed file, default value 2.</li>\r\n<li><strong>Attribute relative cumulative variance</strong> – the amount of variance, which must be preserved. Relative cumulative variance must be in interval (0; 100]%.</li>\r\n</ul>\r\n<h3>MDS SMACOF | Multidimensional scaling (MDS) SMACOF algorithm</h3>\r\n<p>The multidimensional scaling (MDS) is a group of methods that project multidimensional data to a low (usually two) dimensional space and preserve the interpoint distances among data as much as possible. The goal of multidimensional scaling is to find low-dimensional points, such that the distances between he points in the low-dimensional space were as close to the proximities as possible.</p>\r\n<p>The MDS Stress function can be minimized using SMACOF algorithm. SMACOF algorithm is based on iterative majorization. It is one of the best optimisation algorithms for this type of minimization problem. This method is simple and powerful, because it guarantees a monotone convergence of stress function.</p>\r\n<p>The coordinates of two-dimensional vectors are recalculated, taking in to consideration not only the coordinates, obtained in the previous iteration, as in classical SMACOF algorithm, but also the new coordinates, obtained in the current iteration. It is mean that Guttman transform matrix is recalculated after each new changed point. Although the algorithm convergence speed increases, but also increases the time cost.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<ul>\r\n<li><strong>Projection space</strong> (int) – low-dimensional space or projection space; positive integer value, space dimension cannot be greater than quantity of attributes in analysed file, default value 2.</li>\r\n<li><strong>Maximum number of iteration</strong>(int) – maximal iteration number, positive integer value, maximum number of iteration must be in interval [1; 1000], default value 100.</li>\r\n<li><strong>Minimal stress change</strong> (double) – Minimal stress change, obtained between two neighboring iterations, must be in interval [10<sup>-8</sup>; ?), default value 0.0001.</li>\r\n<li><strong>Does apply Seidel modification</strong> (boolen) – if the value is equal „True“, it is applied Zeidel modification; by default Zeidel modification is not applied.</li>\r\n</ul>\r\n<h3>DMA | Diagonal majorization algorithm</h3>\r\n<p>The diagonal majorization algorithm (DMA) is modification of SMACOF algorithm. DMA attains a slightly worse MDS projection error than SMACOF, but computing is faster and requires essentially less computing memory. The DMA uses a simpler majorization function. DMA algorithm is used for visualization of large data sets.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<ul>\r\n<li><strong>Projection space</strong> (int) – low-dimensional space or projection space; positive integer value, space dimension cannot be greater than quantity of attributes in analysed file, default value 2.</li>\r\n<li><strong>Maximum number of iteration</strong>(int) – maximal iteration number, positive integer value, maximum number of iteration must be in interval [1; 1000], default value 100.</li>\r\n<li><strong>Minimal stress change</strong> (double) – minimal stress change, obtained between two neighbouring iterations, must be in interval [10<sup>-8</sup>; ?), default value 0.0001.</li>\r\n<li><strong>Relative number of neighbours</strong> (int) – relative number of neighbours, must be in interval (0; 100] %, default value is 1.</li>\r\n</ul>\r\n<h3>Relative MDS | The relative multidimensional scaling algorithm</h3>\r\n<p>The classical MDS is a topology preserving mapping, but it does not offer a possibility to project new points on the existing set of mapped points. To get a mapping that presents the previously mapped points together with the new ones requires a complete re-run of the MDS algorithm on the new and the old data points. Relative MDS is used for visualization of new data points on the fixed mapping and for the visualization of large data sets</p>\r\n<p>The relative MDS algorithm gives precise mapping and saves much computing time as compared with the standard MDS algorithm when is visualized large data sets. Therefore, in the case of limited computing time, the projection by the relative MDS algorithm will be better than that by the standard MDS algorithm.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<ul>\r\n<li><strong>Projection space</strong> (int) – low-dimensional space or projection space; positive integer value, space dimension cannot be greater than quantity of attributes in analysed file, default value 2.</li>\r\n<li><strong>Maximum number of iteration</strong>(int) – maximal iteration number, positive integer value, maximum number of iteration must be in interval [1; 1000], default value 100.</li>\r\n<li><strong>Minimal stress change</strong> (double) – minimal stress change, obtained between two neighbouring iterations, must be in interval [10<sup>-8</sup>; ?), default value 0.0001.</li>\r\n<li><strong>Relative number of basis objects</strong> (int) – Relative basis object quantity must be in interval (0; 100] %.</li>\r\n<li><strong>Select Basis objects strategy</strong> (int) – the strategies of selecting the basis vectors: Random, By line based on PCA, By line based on max variable. Default value is "random".</li>\r\n</ul>\r\n<p> </p>\r\n<h3>SAMANN | SAMANN algorithm</h3>\r\n<p>SAMANN – an unsupervised backpropagation algorithm to train a multilayer feed-forward neural network (SAMANN) to perform the Sammon''s nonlinear projection. A well-known procedure for mapping data from a high-dimensional space onto a lower-dimensional one is Sammon''s mapping. This algorithm preserves as well as possible all interpattern distances.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<ul>\r\n<li><strong>Projection space</strong> (int) – low-dimensional space or projection space; positive integer value, space dimension cannot be greater than quantity of attributes in analysed file, default value 2.</li>\r\n<li><strong>Maximum number of iteration</strong>(int) – maximal iteration number, positive integer value, maximum number of iteration must be in interval [1; 1000], default value 100.</li>\r\n<li><strong>Relative size of the training data </strong>(int) – <strong>Relative size of the training data</strong> of initial data set for SAMANN neural network; relative size of the training data must be in interval (0; 100] %, default value is 10.</li>\r\n</ul>\r\n<ul>\r\n<li><strong>Number of neurons in the hidden layer</strong>(int) – Number of neurons in the hidden layer of the SAMANN neural network, default value is 10.</li>\r\n<li><strong>Value of the learning rate</strong> (double) – Value of the learning ratemust be in interval [0,1;10], default value is 1.</li>\r\n</ul>\r\n<h3>SOM-MDS | Consequent combination of the self-organizing map (SOM) with multidimensional scaling</h3>\r\n<p>The self-organizing map (SOM) is used for both clustering and visualization of multidimensional data, i.e. mapping data from a high-dimensional space onto a lower-dimensional one. The map preserves topological properties of the input space, such that the cells that are close in the map include data instances that are similar to each other.</p>\r\n<p>The main reason of the combination SOM-MDS is to improve the visualization of SOM. Moreover, such a combination allows to decrease the computation time of visualization as compared with alone MDS, when size of analyzed data setis large. At first, all multidimensional data pointsare processed using SOM, then the obtained reference vectors of the winning neurons are displayed, using one of the MDS methods. Usually, the total numberof winning neurons is smaller than number of analysed data instances.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<ul>\r\n<li><strong>Number of rows of SOM</strong> (int) – Number of rows of self-organizing map, SOM rows  quantity must be in interval [3; 100], default value is 10.</li>\r\n<li><strong>Number of columns of SOM</strong> (int) – Number of colums of self-organizing map, SOM colums  quantity must be in interval [3; 100], default value is 10.</li>\r\n<li><strong>Number of SOM training epochs</strong> (int) –Number of SOM training epochs must be in interval [1; 1000], default value is 100.</li>\r\n<li><strong>Projection space of MDS</strong> (int) - low-dimensional space or projection space; positive integer value, space dimension cannot be greater than quantity of attributes in analysed file, default value 2.</li>\r\n<li><strong>Number of iterations of MDS</strong> (int) - maximal iteration number, positive integer value, maximum number of iteration must be in interval [1; 1000], default value 100.</li>\r\n<li><strong>Minimal stress change </strong>(double) – minimal stress change, obtained between two neighbouring iterations, must be in interval [10<sup>-8</sup>; ?), default value 0.0001.</li>\r\n</ul>\r\n<p> </p>\r\n<h2>Data analysis: Classification, clustering</h2>\r\n<h3>SOM | Self-organizing map (SOM)</h3>\r\n<p>The self-organizing map (SOM) is used for both clustering and visualization of multidimensional data, i.e. mapping data from a high-dimensional space onto a lower-dimensional one. The map preserves topological properties of the input space, such that the cells that are close in the map include data instances that are similar to each other.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<ul>\r\n<li><strong>Number of rows </strong> (int) – Number of rows of self-organizing map, SOM rows  quantity must be in interval [3; 100], default value is 10.</li>\r\n<li><strong>Number of columns </strong> (int) – Number of colums of self-organizing map, SOM colums  quantity must be in interval [3; 100], default value is 10.</li>\r\n<li><strong>Number of training epochs</strong> (int) –Number of SOM training epochs must be in interval [1; 1000], default value is 100.</li>\r\n</ul>\r\n<h4>MLP | <strong>Multilayer perceptron</strong></h4>\r\n<p>A <strong>multilayer perceptron</strong> (MLP) is a classifier, a feed forward artificial neural network model that maps sets of input data onto a set of appropriate outputs. A MLP consists of multiple layers of nodes in a directed graph, with each layer fully connected to the next one. Except for the input nodes, each node is a neuron (or processing element) with a nonlinear activation function. MLP utilizes a supervised learning technique called back-propagation for training the network.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<ul>\r\n<li><strong>Maximum number of iteration </strong>(int) – Maximum number of iteration must be in interval [1; 1000], default value is 100.</li>\r\n<li><strong>Number of neurons </strong><strong>in the hidden layer</strong><strong>(1st layer | 2nd layer)</strong> – Number of neurons in the hidden layers: at layer 1 must be greater than 0, at layer 2  cannot be negative.</li>\r\n<li><strong>Size of training data - </strong>the percentage size of the training set. This value should be greater than or equal to 1, default value is 90 %.</li>\r\n<li><strong>Size of validation data -</strong>Size of test data is calculated automatically, by formula (100 % - Size of training data), default value is 10 %.</li>\r\n<li><strong>Number of folds for cross-validation</strong> (int) - Number of folds for cross-validation</li>\r\n</ul>\r\n<p> </p>\r\n<h4>RDF | Random decision forest</h4>\r\n<p>The RDF algorithm is a modification of the original Random Forest algorithm designed by Leo Breiman and Adele Cutler. Two ideas are in combination with each other in this algorithm: these are the use of a decision tree committee getting the result by voting, and the idea of training process randomization.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<ul>\r\n<li><strong>Pasikliovimo lygmuo</strong> (double) – pasikliovimo lygmuo, įvertinant klaidos tikimybės pasikliautinąjį intervalą.</li>\r\n<li><strong>Mokymo aibės dydis</strong> (int) – mokymo objektų skaičius.</li>\r\n<li><strong>Testavimo aibės dydis</strong> (int) – testavimo objektų skaičius.</li>\r\n</ul>\r\n<h4>K-means | k-means clustering</h4>\r\n<p>k-means clustering aims to partition the points into <em>k</em> groups such that the sum of squares from points to the assigned cluster centres is minimized. At the minimum, all cluster centres are at the mean of their Voronoi sets (the set of data points which are nearest to the cluster centre).</p>\r\n<p><strong>Parameters:</strong></p>\r\n<ul>\r\n<li><strong>Maximum number of iteration (int) </strong>– Number of iteration must be in interval [1; 1000], default valu eis 100.</li>\r\n<li><strong>Maximum number of cluster (int)</strong>– Number of cluster must be in interval [1; 100], default value is 10.</li>\r\n</ul>\r\n<p> </p>\r\n<h2>View results</h2>\r\n<h3>Technical details</h3>\r\n<p>the component "Technical details" is used to view for technical information: computation time, report about errors and so on. You can view the obtained results after the experiment execution.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<p>This component does not have control parameters.</p>\r\n<h3>Matrix view</h3>\r\n<p>Matrix view component is used to view upload data, obtained results of experiments (in table form). Matrix view component is connected to the upload file component or with the component of selected algorithm.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<p>This component does not have control parameters.</p>\r\n<h3>Chart view</h3>\r\n<p>Chart view component is used to view scatterplot of the obtained results. This component is connected with component of selected data mining algorithm. The user can view the obtained results after the experiment execution.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<p>This component does not have control parameters.</p>', 5, '2014-06-02 16:44:40', '2014-06-05 14:01:06', 'en');
    (2, 'FAQ', 'faq', 'help', '<div class="offset1 span9">\r\n<h2>Frequently Asked Questions</h2>\r\n<p><strong>What is DAMIS?</strong></p>\r\n<p>DAMIS – Web Service Based Data Mining Tool for Multidimensional Data Analysis. DAMIS is a pilot user-friendly Web-based solution for planning and executing data mining experiments in remote multi-core computational clusters. It is a scientist''s tool, including a collection of ready-to-use research-based data mining algorithms, data upload and storing services, data retrieval from the MIDAS e-Infrastructure, a visual experiment work-flow editor and results visualization tools.</p>\r\n<p><strong>What methods of data analysis are available in DAMIS tool? <br /></strong></p>\r\n<p>It is possible to use these methods of data analysis in DAMIS tool:</p>\r\n<ul>\r\n<li>Principal component analysis (PCA);</li>\r\n<li>Multidimensional scaling (MDS) SMACOF algorithm;</li>\r\n<li>Zeilel’s modification of MDS SMACOF;</li>\r\n<li>Diagonal majorization algorithm (DMA);</li>\r\n<li>Relative multidimensional scaling algorithm;</li>\r\n<li>SAMANN – an unsupervised backpropagation algorithm to train a multilayer feed-forward neural network (SAMANN) to perform the Sammon''s nonlinear projection;</li>\r\n<li>Self-organizing map (SOM);</li>\r\n<li>Consequent combination of the self-organizing map (SOM) with multidimensional scaling;</li>\r\n<li>A multilayer perceptron (MLP) - a classifier, a feed forward artificial neural network model that maps sets of input data onto a set of appropriate outputs;</li>\r\n<li>Random decision forest classifier;</li>\r\n<li>K-means algorithm for clustering.</li>\r\n</ul>\r\n<h4>How to use uploaded data file in experiment workflow?</h4>\r\n<p>Component "EXISTING DATA" is used for this purpose. Firstly you have to drag this component to the experiment workflow, double click on it and choose your uploaded file from dropdown menu. Now you can construct rest of your experiment.</p>\r\n<h4>How to see experiment results after experiment execution?</h4>\r\n<p>You have to join one of "VIEW RESULTS" component to the ending of your experiment workflow. When experiment finishes its execution "VIEW RESULTS" components become active, if you double click on them results will be displayed.</p>\r\n<p><strong>What formats of supported file can we upload on DAMIS?</strong></p>\r\n<p>It is possible to upload data table from a supported file formats: tab, txt, csv, ARFF and XML files, which are compressed in zip format.</p>\r\n<p>Requirements for data file: A dataset is roughly equivalent to a two-dimensional spreadsheet or database table. A dataset is a collection of instances, where each instance consists of a number of attributes. The external representation of an instances class is an ARFF file, which consists of a header describing the attribute types and the data as comma-separated list.</p>\r\n<p>Also, the user has the possibility to edit or delete already uploaded files. Selecting the file management tab is displayed the list of uploaded data files: names and sizes of stored files. The list of uploaded data files can be sorted according to the names of data files and the date of upload. A user can download to his computer uploaded files and the results files, obtained after the experiment execution, in the following formats: arff, zip, tab, csv, xls, xlsx.</p>\r\n<p><strong>Why to use ARFF file format of analysed data for the work with the DAMIS tool is better? How to describe the upload data?</strong></p>\r\n<p>In order to avoid errors and other inconveniences, it is advisable to choose the ARFF file format. An ARFF (Attribute-Relation File Format) file is an ASCII text file that describes a list of instances sharing a set of attributes.</p>\r\n<p>ARFF files have two distinct sections: the Header information and the Data information.</p>\r\n<p>The Header of the ARFF file contains the name of the relation (@RELATION), a list of the attributes (@ATTRIBUTE) (the columns in the data), and their types (NUMERIC (real or integer), STRING, DATE). Lines that begin with a % are comments. The @RELATION, @ATTRIBUTE and @DATA declarations are case insensitive.</p>\r\n<p>An example header on the standard IRIS dataset looks like this: </p>\r\n<pre>@RELATION iris\r\n\r\n   @ATTRIBUTE sepallength  NUMERIC\r\n   @ATTRIBUTE sepalwidth   NUMERIC\r\n   @ATTRIBUTE petallength  NUMERIC\r\n   @ATTRIBUTE petalwidth   NUMERIC\r\n   @ATTRIBUTE class        {Iris-setosa,Iris-versicolor,Iris-virginica}</pre>\r\n<p>The Data of the ARFF file looks like the following:</p>\r\n<pre>@DATA\r\n   5.1,3.5,1.4,0.2,Iris-setosa\r\n   4.9,3.0,1.4,0.2,Iris-setosa\r\n   4.7,3.2,1.3,0.2,Iris-setosa\r\n   4.6,3.1,1.5,0.2,Iris-setosa\r\n   5.0,3.6,1.4,0.2,Iris-setosa</pre>\r\n<p>Missing values are represented by a single question mark, as in: </p>\r\n<pre> @DATA\r\n   ?,3.5,?,0.2,Iris-setosa</pre>\r\n<p><strong>How do I view the results of my experiments?</strong></p>\r\n<p>For viewing of the obtained results you can use three components:</p>\r\n<ul>\r\n<li><strong>“Technical details” - </strong>the componentis used to view for technical information: computation time, report about errors and so on. You can view the obtained results after the experiment execution. This component is connected with component of selected data mining algorithm.</li>\r\n<li><strong>“Matrix view” </strong>- Matrix view component is used to view upload data, obtained results of experiments (in table form). Matrix view component is connected to the upload file component or component of selected algorithm.</li>\r\n<li><strong>“Chart view” – </strong>Chart view component is used to view scatterplot of the obtained results. This component is connected with component of selected data mining algorithm. You can view the obtained results after the experiment execution.</li>\r\n</ul>\r\n<p>User can double click on the one of these component and view obtained results of experiment. Also, user can download the obtained results to his computer using <strong>Technical detail</strong> or <strong>Matrix view</strong> component.</p>\r\n<p><strong>How can user perform an experiment on DAMIS with </strong><strong>own</strong><strong> data set?</strong></p>\r\n<p>The experiment planning and execution environment is available to an authenticated user. The user can compose experiments by dragging algorithms from the tool on the left to the working area, providing parameters by double clicking the corresponding icon and filling in the parameters form and connecting the icons.</p>\r\n<p>The user drags the <strong>Upload new file</strong> component to the working area and double clicks it to select his dataset. Then, the user chooses all necessary components from tool and connects them step by step, according the plan of his experiment. Finally, the user chooses to view the obtained result using one of <strong>View results</strong> components, which gives a representation of the algorithm results. The user clicks the <strong>Execute</strong> button when he finishes editing. A work-flow is validated, analyzed and remote services, corresponding to each of the algorithms, are called. The results are available by double clicking the <strong>View result</strong> component.</p>\r\n<p>If it is found an error in the sequence, an error message appears above the component, in which the error is occurred, or the component, in which the control parameters is entered incorrectly, is colored in red.</p>\r\n<p><strong>How to know if the results of my experiment are already formed?</strong></p>\r\n<p>When the user finishes editing his experiments workflow, save it with new name and clicks the <strong>Execute</strong> button on the bottom of workflow, this new experiment appears in the list of experiments history in tab EXPERIMENTS. The new experiment is gaining the status of "Executing”. When new experiment is gaining the status of “Finished”, the obtained results will be available for viewing.</p>\r\n<p><strong>Can the user analyse a data file with missing values using DAMIS tool?</strong></p>\r\n<p>The user drags the Upload new file component to the working area and double clicks it to select his dataset. If the analysed data set has missing values, it is necessary to clean data using cleaning data component. The user drags the Clean data component to the working area and connects it with the Upload new file component. At the moment if missing object data is found, then this object will be eliminated from the further calculations. In this way it is ensured that all data records will have values and are suitable for further analysis.</p>\r\n<p><strong>How to recover a forgotten Password of DAMIS account?</strong></p>\r\n<p>It is possible to reset your password. From the LOGIN tab click link <strong>Forgot password? </strong></p>\r\n<p>Enter the email address you used to create the account and an email will be sent with a link you can use to reset your password.</p>\r\n<p><strong>I would like to know the running time of the algorithm</strong><strong>after experiment execution. How to do it?</strong></p>\r\n<p><strong>“Technical details” - </strong>the componentis used to view for technical information: computation time, report about errors and so on. You can view the obtained results after the experiment execution. This component is connected with component of selected data mining algorithm.</p>\r\n</div>', 2, '2014-03-17 16:22:46', '2014-06-06 08:46:47', 'en'),
    (3, 'Pagalba', 'pagalba', 'help', '<h2>Duomenų įkėlimas</h2>\r\n<h3>Įkelti naują failą</h3>\r\n<p>Galimybė įkelti failą iš naudotojo kompiuterio.</p>\r\n<p>Failus galima pateikti šiais formatais: tab, txt, csv, ARFF ir XML failai suarchyvuoti zip formatu. Reikalavimai duomenų failui: atskirų objektų požymių įverčiai pateikiami atskirose eilutėse, bei objekto požymių įverčiai eilutėje atskiriami tarpais arba specialiais simboliais.</p>\r\n<h3>Pasirinkti įkeltą failą</h3>\r\n<p>Galimybė pasinaudoti jau į sistemą įkeltais duomenų failais.</p>\r\n<h3>Įkelti failą iš MIDAS</h3>\r\n<p>Galimybė įkelti failą iš MIDAS archyvo.</p>\r\n<h2>Pirminis apdorojimas</h2>\r\n<h3>Valymas | Duomenų valymas</h3>\r\n<p>Tai veikla, kurios metu yra užtikrinama, kad duomenys turi vientisą struktūrą ir yra tinkami tolimesniam apdorojimui:</p>\r\n<p>Perskaičius duomenų ARFF failą patikrinamas duomenų vektorių atributų duomenų tipų atitikimas meta informacijoje deklaruotiems duomenų tipams, taip pat atliekamas trūkstamų reikšmių duomenų dalyje, patikrinimas. Šio duomenų valymo metu apie aptiktas klaidas yra suformuojamas pranešamas naudotojui ir tolimesnis komponenčių vykdymas sustabdomas. Taip yra užtikrinama, kad visi duomenų įrašai turės reikšmes ir bus tinkami tolimesniam apdorojimui.</p>\r\n<p>Parametrai:</p>\r\n<p><strong>Ši komponentė neturi valdymo parametrų.</strong></p>\r\n<p><strong> </strong></p>\r\n<h3>Filtravimas | Duomenų filtravimas</h3>\r\n<p>Filtravimas yra tam tikromis savybėmis pasižyminčių įrašų atmetimas iš nagrinėjamų įrašų aibės. Filtravimo rezultatu gali būti arba duomenų aibė be išsiskiriančių objektų, arba objektai atsiskyrėliai. Vykdant filtravimo komponentę galima pasirinkti pagal kokį vieną požymį bus atliekamas filtravimas ir kokia yra slenksčio reikšmė (kvantilis).</p>\r\n<p>Parametrai:</p>\r\n<ul>\r\n<li><strong>Filtravimo rezultatas</strong> – be atsiskyrėlių; tik atsiskyrėliai.</li>\r\n<li><strong>Z reikšmė – </strong>leistinos yra teigiamos parametro Z reikšmės (nebūtinai sveikieji skaičiai).</li>\r\n<li><strong>Požymis</strong> – galimybė pasirinkti norimą požymį pagal kurį bus atliekamas filtravimas.</li>\r\n</ul>\r\n<p><strong> </strong></p>\r\n<h4>Skaidymas | Pradinės duomenų aibės skaidymas į smulkesnius poaibius</h4>\r\n<p>Duomenų skaidymas – pradinės duomenų aibės skaidymas į smulkesnius poaibius. Gautuosius poaibius galima apdoroti lygiagrečiai arba nagrinėti vieną iš jų, pavyzdžiui imtis gali atspindėti populiacijos dėsningumus.</p>\r\n<p>Duomenų aibės skaidymo būdai:</p>\r\n<ol>\r\n<li>Nekeisti analizuojamos duomenų aibės objektų tvarkos ir aibė dalinama į du poaibius pasirinktu  santykiu.</li>\r\n<li>Pradinės duomenų aibės objektai perrikiuojami atsitiktine tvarka ir tuomet dalinama į du poaibius pasirinktu santykiu.</li>\r\n</ol>\r\n<p><strong>Parametrai:</strong></p>\r\n<ul>\r\n<li><strong>Objektų rikiavimo tipas – Tvarka nekeičiama </strong>(objektų išdėstymo tvarka nebus keičiama<strong>); Atsitiktinis </strong>(objektų išdėstymo tvarka bus keičiama atsitiktine tvarka)<strong>.</strong></li>\r\n<li><strong>Pirmojo poaibio dydis –</strong> reikia pasirinkti pirmojo poaibio santykinį dydį.</li>\r\n<li><strong>Antrojo poaibio dydis – </strong>antrasis poaibio dydis skaičiuojamas automatiškai taip, kad abiejų poaibių dydžių suma būtų lygi 100 %.</li>\r\n</ul>\r\n<p><strong> </strong></p>\r\n<h3>Transponavimas</h3>\r\n<p>Duomenų transponavimas –procesas, kurio metu gaunama nauja duomenų matrica iš pradinės, pakeičiant kiekvieną jos eilutę (stulpelį) stulpeliu (eilute) turinčiu tą patį indeksą.</p>\r\n<p><strong>Parametrai:</strong></p>\r\n<p><strong>Ši komponentė neturi valdymo parametrų.</strong></p>\r\n<p><strong> </strong></p>\r\n<h3>Normavimas | Duomenų normavimas</h3>\r\n<p>Normavimas – tai duomenų reikšmių keitimas kitomis. Galimi du būdai:</p>\r\n<ul>\r\n<li>Pagal vidurkį ir dispersiją, kai reikšmės pakeičiamos taip, kad kiekvieno požymio vidurkiai būtų lygūs 0, o dispersija – 1</li>\r\n<li>Normavimas į intervalą – reikšmių intervalų keitimas, kai reikšmės pakeičiamos taip, kad kiekvieno požymio minimalios ir maksimalios reikšmės būtų intervale [a, b].</li>\r\n</ul>\r\n<p><strong>Parametrai:</strong></p>\r\n<ul>\r\n<li><strong>Vidurkis a, dispersija b </strong>– normavimas pagal vidurkį ir dispersiją, kai reikšmės pakeičiamos taip, kad kiekvieno požymio vidurkiai būtų lygūs 0 (parametras a), o dispersija – 1 (parametras b).</li>\r\n<li><strong>Intervalas [a; b] – </strong>reikšmių intervalų keitimas, kai reikšmės pakeičiamos taip, kad kiekvieno požymio minimalios ir maksimalios reikšmės būtų intervale [a, b].</li>\r\n</ul>\r\n<h3>Požymių atrinkimas</h3>\r\n<p> Požymių atrinkimo komponentė suformuoja naują duomenų aibę, sudarytą iš pasirinktų analizuojamos aibės požymių (atributų) reikšmių. Taip pat numatyta naujajame faile klase paskelbti bet kokį požymį.</p>\r\n<p><strong>Parametrai:</strong></p>\r\n<ul>\r\n<li><strong>Atrinkti požymiai - </strong>pasirenkama požymių aibė iš kurios bus formuojama nauja duomenų aibė. Numatyta reikšmė - tuščias sąrašas.<strong><br /></strong></li>\r\n<li><strong><strong>Klasės požymis</strong> - </strong>naujajame faile klase paskelbiamas bet koks pasirinktas požymis. Numatyta reikšmė - nepasirinktas joks požymis.</li>\r\n</ul>\r\n<p> </p>\r\n<h2>Statistiniai primityvai</h2>\r\n<h3>Statistiniai primityvai | Statistinių primityvų skaičiavimas</h3>\r\n<p>Apskaičiuojami analizuojamų duomenų statistiniai primityvai: min, max, vidurkis, standartinis nuokrypis, mediana.</p>\r\n<p>Parametrai:</p>\r\n<p><strong>Šį komponentė neturi valdymo parametrų.</strong></p>\r\n<p> </p>\r\n<h2>Dimensijos mažinimas</h2>\r\n<h3>PCA | Pagrindinių komponenčių analizė</h3>\r\n<p>Pagrindinių komponenčių analizė (angl. principal component analysis, PCA) yra klasikinis statistikos metodas. Tai tiesinė duomenų transformacija, plačiai naudojama duomenų analizei kaip daugiamačių duomenų dimensijos mažinimo metodas.</p>\r\n<p>Pagrindinė pagrindinių komponenčių analizės idėja yra sumažinti duomenų dimensiją atliekant tiesinę transformaciją ir atsisakant dalies po transformacijos gautų naujų komponenčių, kurių dispersijos yra mažiausios. Iš pradžių ieškoma krypties, kuria dispersija yra didžiausia. Didžiausią dispersiją turinti kryptis vadinama pirmąja pagrindine komponente. Ji eina per duomenų centrinį tašką. Tai taškas, kurio komponentės yra analizuojamą duomenų aibę sudarančių taškų atskirų komponenčių vidurkiai. Visų taškų vidutinis atstumas iki šios tiesės yra minimalus, t. y., ši tiesė yra kiek galima arčiau visų duomenų taškų. Antrosios pagrindinės komponentės ašis taip pat turi eiti per duomenų centrinį tašką ir ji turi būti statmena pirmosios pagrindinės komponentės ašiai.</p>\r\n<p>Parametrai:</p>\r\n<ul>\r\n<li><strong>Projekcijos dimensija</strong> – nurodoma sumažinta pradinių duomenų dimensija (<strong>dimensija</strong>). Dimensija negali būti neigiamas skaičius, taip pat, jei pasirinkimas yra „Dimensija“ įvestos dimensijos reikšmė negali būti didesnė nei arff faile esančių požymių skaičius.</li>\r\n<li><strong>Požymių santykinė suminė dispersija</strong> – dispersijos dalis, kurią norima išlaikyti (<strong>dispersija</strong>). Santykinės suminės dispersijos galimos reikšmės yra intervale (0; 100] %.</li>\r\n</ul>\r\n<p> </p>\r\n<h3>SMACOF (MDS) | SMACOF (MDS) algoritmas</h3>\r\n<p>Tai vienas geriausių optimizavimo algoritmų, taikomų daugiamačių skalių paklaidos minimizavimui. Algoritmas yra paprastas, bet efektyvus, kadangi garantuoja paklaidos funkcijos konvergavimą į lokalų minimumą su tiesiniu konvergavimo greičiu.</p>\r\n<p>SMACOF algoritmui buvo pritaikytas Gauso Zeidelio metodas. Modifikacijos esmė –nauji projekcijos taškai iteracinio proceso eigoje apskaičiuojami, remiantis jau prieš tai toje pačioje iteracijoje apskaičiuotais taškais. Tai reiškia, kad Gutmano transformacijos matrica perskaičiuojama po kiekvieno pakeisto taško. Nors tokio algoritmo konvergavimo greitis išauga, tačiau išauga ir laiko sąnaudos.</p>\r\n<p>Parametrai:</p>\r\n<ul>\r\n<li><strong>Projekcijos dimensija</strong>– nurodoma sumažinta pradinių duomenų dimensija (projekcijos dimensija).</li>\r\n<li><strong>Maksimalus iteracijų skaičius</strong>– maksimalus iteracijų skaičius. Maksimalus iteracijų skaičius yra 1000.</li>\r\n<li><strong>Skirtumas tarp paklaidų, gautų tarp gretimų iteracijų</strong>  – Skirtumas tarp paklaidų, gautų tarp gretimų iteracijų. Skirtumas tarp paklaidų intervale nustatomas iš intervalo [10e-8; ?).</li>\r\n<li><strong>Ar taikyti Zeidelio modifikaciją (TAIP | NE)</strong> – Parametras, kuris nurodo taikyti arba netaikyti Zeidelio modifikaciją. reikšmė „True“, jei taikoma Zeidel modifikacija; jei nenurodyta kitaip, Zeidel modifikacija nebus taikoma.</li>\r\n</ul>\r\n<p> </p>\r\n<h3>DMA | Diagonalinio mažoravimo algoritmas</h3>\r\n<p>Diagonalinio mažoravimo algoritmas (DMA) yra SMACOF algoritmo modifikacija, kurioje naudojama paprastesnė mažoravimo funkcija. SMACOF – tai vienas geriausių optimizavimo algoritmų, taikomų daugiamačių skalių paklaidos minimizavimui. Modifikacija DMA skirta atvaizduoti didesnėms duomenų aibėms.</p>\r\n<p>Parametrai:</p>\r\n<ul>\r\n<li><strong>Projekcijos dimensija </strong>– nurodoma sumažinta pradinių duomenų dimensija (projekcijos dimensija).</li>\r\n<li><strong>Maksimalus iteracijų skaičius</strong> – maksimalus iteracijų skaičius. Maksimalus iteracijų skaičius yra 1000.</li>\r\n<li><strong>Skirtumas tarp paklaidų, gautų tarp gretimų iteracijų</strong> – Skirtumas tarp paklaidų, gautų tarp gretimų iteracijų. Skirtumas tarp paklaidų intervale nustatomas iš intervalo [10e-8; ?).</li>\r\n<li><strong>Santykinis kaimynų skaičius</strong>– nurodomas kaimynų skaičius.</li>\r\n</ul>\r\n<p> </p>\r\n<h3>Relative MDS | Santykinių daugiamačių skalių algoritmas</h3>\r\n<p>Santykinių daugiamačių skalių algoritmas (angl. Relative MDS) skirtas didelių aibių bei naujų taškų priklausančių daugiamatei erdvei vizualizavimui, naudojant prieš tai apskaičiuotą bazinių taškų projekciją.</p>\r\n<p>Naudojant klasikinį daugiamačių skalių metodą, negalima atidėti naujo taško neperskaičiuojant visos turimos duomenų aibės projekcijos. Todėl naujų taškų atvaizdavimui gali būti naudojamas santykinių daugiamačių skalių algoritmas (SDS). Nors šis metodas nėra toks tikslus kaip SMACOF, tačiau jis gali atvaizduoti dideles aibes, tam pareikalaudamas mažai kompiuterio skaičiavimo resursų.</p>\r\n<p>Parametrai:</p>\r\n<ul>\r\n<li><strong>Projekcijos dimensija </strong>– nurodoma sumažinta pradinių duomenų dimensija (projekcijos dimensija).</li>\r\n<li><strong>Maksimalus iteracijų skaičius</strong> – maksimalus iteracijų skaičius. Maksimalus iteracijų skaičius yra 1000.</li>\r\n<li><strong>Skirtumas tarp paklaidų, gautų tarp gretimų iteracijų</strong> – Skirtumas tarp paklaidų, gautų tarp gretimų iteracijų. Skirtumas tarp paklaidų intervale nustatomas iš intervalo [10e-8; ?).</li>\r\n<li><strong>Bazinių objektų skaičius </strong>– bazinių objektų skaičiaus nustatymas.</li>\r\n<li><strong>Bazinių objektų parinkimas (Atsitiktinis | Pagal PCA (dimensija 1) | Pagal didžiausių požymių dispersiją)</strong> – bazinių objektų parinkimo strategija.</li>\r\n</ul>\r\n<p> </p>\r\n<h3>SAMANN | SAMANN algoritmas</h3>\r\n<p>SAMANN – specifinė „klaidos skleidimo atgal“ mokymo taisyklė, kuri leidžia įprastam tiesioginio skleidimo neuroniniam tinklui realizuoti Sammon‘o projekciją mokymo be mokytojo būdu. Sammon‘o projekcija yra netiesinis daugelio kintamųjų objektų atvaizdavimo žemesnio matavimo erdvėje metodas. Jo idėja: atvaizduoti daugiamačius vektorius mažesnio matavimo erdvėje išlaikant santykinai panašius atstumus tarp vektorių.</p>\r\n<p>Parametrai:</p>\r\n<ul>\r\n<li><strong>Projekcijos dimensija </strong>– nurodoma sumažinta pradinių duomenų dimensija (projekcijos dimensija).</li>\r\n<li><strong>Maksimalus iteracijų skaičius</strong> – maksimalus iteracijų skaičius. Maksimalus iteracijų skaičius yra 1000.</li>\r\n<li><strong>Apmokymo aibės dydis </strong>– SAMANN neuroninio tinklo apmokymui naudojamų pradinės aibės elementų skaičius.</li>\r\n<li><strong>Paslėptojo sluoksnio neuronų skaičius </strong>– SAMANN neuroninio tinklo paslėptojo sluoksnio neuronų skaičius.</li>\r\n<li><strong>Mokymo greičio parametras</strong>– mokymosi greičio parametro reikšmė (iš intervalo 0,1–10).</li>\r\n</ul>\r\n<p> </p>\r\n<h3>SOM-MDS | Saviorganizuojančių neuroninių tinklų junginys su daugiamatėmis skalėmis</h3>\r\n<p>SOM žemėlapiai naudojami ir daugiamačiams duomenims klasterizuoti ir juos vizualizuoti, t. y. rasti projekcijas mažesnės dimensijos erdvėje, įprastai plokštumoje. SOM tinklo tikslas – išlaikyti duomenų kaimyniškumus, t. y. taškai, esantys arti įėjimo vektorių erdvėje, turi būti atvaizduojami arti vieni kitų ir SOM žemėlapyje. Kartais gautus rezultatus sudėtinga interpretuoti, todėl jie papildomai analizuojami vienu iš daugiamačių duomenų projekcijos metodu. Tuo tikslu gali būti naudojamas daugiamačių skalių metodas (MDS). Vienas iš nuosekliojo junginio tikslų – pagerinti duomenų vizualizavimą, panaudojant saviorganizuojančius neuroninius tinklus. Tačiau pagrindinis nuosekliojo junginio tikslas – sumažinti skaičiavimo laiką, neprarandant vizualizavimo kokybės, atvaizduojant neuronus–nugalėtojus atitinkančius vektorius, gautus taikant SOM ir juos vizualizuojant MDS metodu, lyginant su visos duomenų aibės vizualizavimo laiku, taikant tik MDS metodą</p>\r\n<p>Parametrai:</p>\r\n<ul>\r\n<li><strong>Eilučių skaičius </strong>– Saviorganizuojančio neuroninio tinklo eilučių skaičius.</li>\r\n<li><strong>Stulpelių skaičius </strong>– Saviorganizuojančio neuroninio tinklo stulpelių skaičius.</li>\r\n<li><strong>SOM mokymo epochų skaičius</strong> – mokymo epochų skaičius.</li>\r\n<li><strong>MDS projekcijos dimensija </strong>– nurodoma sumažinta pradinių duomenų dimensija (projekcijos dimensija).</li>\r\n<li><strong>MDS iteracijų skaičius</strong> – MDS iteracijų skaičius.</li>\r\n<li><strong>Skirtumas tarp paklaidų, gautų tarp gretimų iteracijų</strong> – Skirtumas tarp paklaidų, gautų tarp gretimų iteracijų. Skirtumas tarp paklaidų intervale nustatomas iš intervalo [10e-8; ?).</li>\r\n</ul>\r\n<p> </p>\r\n<h2>Klasifikavimas, grupavimas</h2>\r\n<h3>SOM | Saviorganizuojantis neuroninis tinklas</h3>\r\n<p>SOM žemėlapiai naudojami daugiamačiams duomenims vizualizuoti (t. y. rasti projekcijas mažesnės dimensijos erdvėje, įprastai plokštumoje) ir klasterizuoti. SOM tinklo tikslas – išlaikyti duomenų kaimyniškumus, t. y. taškai, esantys arti įėjimo vektorių erdvėje, turi būti atvaizduojami arti vieni kitų ir SOM žemėlapyje.</p>\r\n<p> </p>\r\n<p>Parametrai:</p>\r\n<ul>\r\n<li><strong>Eilučių skaičius </strong>– Saviorganizuojančio neuroninio tinklo eilučių skaičius.</li>\r\n<li><strong>Stulpelių skaičius </strong>– Saviorganizuojančio neuroninio tinklo stulpelių skaičius.</li>\r\n<li><strong>Mokymo epochų skaičius</strong> – mokymo epochų skaičius.</li>\r\n</ul>\r\n<p> </p>\r\n<h3>MLP | Daugiasluoksnis perceptronas</h3>\r\n<p>Daugiasluoksnis perceptronas (DSP) (angl. Multilayer perceptron) yra tiesioginio sklidimo neuroninis tinklas, apmokomas klaidos sklidimo atgal (angl. error back-propagation) metodu. Daugiasluoksnis perceptronas taikomas klasifikavimo uždaviniams spręsti.</p>\r\n<p>Parametrai:</p>\r\n<ul>\r\n<li><strong>Maksimalus iteracijų skaičius </strong>– maksimalus mokymo iteracijų skaičius.</li>\r\n<li><strong>Neuronų skaičius paslėptuose sluoksniuose (1-as sluoksnis | 2-as sluoksnis)</strong> – nurodomos neuronų skaičius paslėptuose sluoksniuose.</li>\r\n<li><strong>Mokymo objektų kiekis</strong>– nurodomas pradinės duomenų aibės mokymo objektų skaičius.</li>\r\n<li><strong>Testavimo objektų kiekis</strong> – nurodomas pradinės duomenų aibės testavimo objektų skaičius.</li>\r\n</ul>\r\n<p> </p>\r\n<h3>Atsitiktinių miškų klasifikatorius | Atsitiktinių miškų klasifikatorius</h3>\r\n<p>Atsitiktinis miškas (angl. <em>random forest</em>) yra populiarus ir efektyvus sprendimo medžių grupės klasi?kavimo algoritmas. Pagrindinė atsitiktinio miško formavimo idėja yra tokia, kad reikia suformuoti tikslų klasi?katorių, apjungiant sprendimus daugelio binarinių sprendimų medžių, užaugintų naudojant skirtingus duomenų poaibius iš originalios duomenų aibės, ir atsitiktinai parinktus požymių poaibius iš požymių aibės. Toks binarinių medžių rinkinys pasižymi atsparumu persimokymui ir, medžių skaičiui augant, generalizavimo klaidos konvergavimu iki stabilios reikšmės.</p>\r\n<p>Parametrai:</p>\r\n<ul>\r\n<li><strong>Pasikliovimo lygmuo</strong> (double) – pasikliovimo lygmuo, įvertinant klaidos tikimybės pasikliautinąjį intervalą.</li>\r\n<li><strong>Mokymo objektų kiekis</strong>– nurodomas pradinės duomenų aibės mokymo objektų skaičius.</li>\r\n<li><strong>Testavimo objektų kiekis</strong> – nurodomas pradinės duomenų aibės testavimo objektų skaičius.</li>\r\n</ul>\r\n<p> </p>\r\n<h3>K-means | k-vidurkių klasterizavimo metodas</h3>\r\n<p>K-vidurkių metodas yra grupavimo algoritmas, skirtas suskirstyti duomenų aibę į kompaktiškas grupes, esančias kuo toliau viena nuo kitos. Paprastai nurodomas parametras k, pasakantis į kiek grupių reikia padalinti vektorių aibę.</p>\r\n<p>Parametrai:</p>\r\n<ul>\r\n<li><strong>Maksimalus iteracijų skaičius</strong> – maksimalus iteracijų skaičius.</li>\r\n<li><strong>Maksimalus klasterių skaičius </strong>– maksimalus galimas grupių skaičius.</li>\r\n</ul>\r\n<p> </p>\r\n<h2>Rezultatų peržiūra</h2>\r\n<h3>Techninė informacija</h3>\r\n<p>Gautų rezultatų techninė informacija.</p>\r\n<h3>Matricinis vaizdavimas</h3>\r\n<p>Gautų rezultatų matricinis vaizdavimas.</p>\r\n<h3>Grafinis vaizdavimas</h3>\r\n<p>Gautų rezultatų grafinis vaizdavimas.</p>', 3, '2014-03-17 17:00:54', '2014-07-07 14:27:28', 'lt'),
    (4, 'DUK', 'duk', 'help', '<div class="offset1 span9">\r\n<h2>Dažnai užduodami klausimai</h2>\r\n<h4>Kas yra DAMIS?</h4>\r\n<p>DAMIS (duomenų analizės įrankis) – tai atvira mokslo infrastruktūra, skirta duomenų analizei atlikti. Įrankio paskirtis – sudaryti galimybę atlikti pagrindinius duomenų analizės tyrimus (grupavimą, klasifikavimą ir kt.); vizualios analizės priemonėmis tirti daugiamačių duomenų projekcijas į plokštumą, duomenų grupavimąsi, duomenų panašumus, atskirų daugiamačių duomenų požymių įtaką ir tarpusavio priklausomybes; stebėti bei apdoroti vizualizacijos ar našiųjų skaičiavimų aplinkoje gautus tyrimų rezultatus.</p>\r\n<h4>Kokie duomenų analizės metodai yra prieinami DAMIS įrankyje?</h4>\r\nDAMIS įrankyje šiuo metu yra prieinami šie duomenų analizės metodai:\r\n<ul>\r\n<li>Pagrindinių komponenčių analizės (PCA) algoritmas.</li>\r\n<li>Daugiamačių skalių grupei (MDS) priklausantis klasikinis SMACOF algoritmas.</li>\r\n<li>SMACOF algoritmo Zeidelio modifikacija.</li>\r\n<li>Diagonalinis mažoravimo algoritmas (DMA).</li>\r\n<li>Santykinės daugiamatės skalės.</li>\r\n<li>Dirbtiniais neuroniniais tinklais ir daugiamatėmis skalėmis grindžiamas SAMANN algoritmas.</li>\r\n<li>Saviorganizuojančiais neuroniniais tinklais (SOM) grindžiamas algoritmas.</li>\r\n<li>MDS ir SOM junginys.</li>\r\n<li>Daugiasluoksnis perceptronas grindžiamas klaidos sklidimo atgal taisykle.</li>\r\n<li>Atsitiktinių miškų (random forest) klasifikatorius</li>\r\n<li>K-vidurkių (k-means) algoritmas.</li>\r\n</ul>\r\n<h4>Kaip eksperimente panaudoti prieš tai įkeltą duomenų failą?</h4>\r\n<p>Eksperimento metu norint panaudoti prieš tai įkeltą duomenų failą prie eksperimento darbų sekos reikia prijungti komponentę  "Pasirinkti įkeltą failą".</p>\r\n<h4>Kokiais formatais turi būti pateikiami sistemai duomenis?</h4>\r\n<p>DAMIS įrankiui duomenys gali būti pateikiami šiais formatais: arff, tab, txt, csv, XML, xls, zip. Taip pat naudotojas turi galimybę redaguoti arba ištrinti jau įkeltus failus. Pasirinkus failų valdymo skiltį yra rodomas jau įkeltų duomenų failų sąrašas, kuriame pateiktas kiekvieno saugomo failo pavadinimas ir dydis. Failų sąrašą galima rūšiuoti pagal duomenų failų pavadinimus, įkėlimo datą. Įkeltus ir gautus rezultatų failus po darbų sekų įvykdymo naudotojas gali atsiųsti į savo kompiuterį arba patalpinti MIDAS archyve šiais formatai: arff, zip, tab, csv, xls, xlsx.</p>\r\n<h4>Kodėl darbui su DAMIS įrankiu geriau pasirinkti ARFF formato failą ir kaip geriau aprašyti duomenis?</h4>\r\n<p>Norint išvengti klaidų ir kitų nepatogumų, patartina pasirinkti ARFF formato failą. ARFF (Attribute-Relation File Format) failas – ASCII tekstinis failas, kuriame objektai, sudarantys konkrečią analizuojamų objektų aibę, yra apibūdinami bendrais požymiais. ARFF failas sudarytas iš dviejų dalių: antraštė ir duomenys.</p>\r\n<p>ARFF failo antraštę sudaro: informacija apie duomenų aibės pavadinimą (@RELATION), požymių sąrašas (@ATTRIBUTE) ir jų tipai (NUMERIC (real arba integer), STRING, DATA, &lt;galimų_reikšmių_aibė&gt;):</p>\r\n<pre>   @RELATION iris\r\n\r\n   @ATTRIBUTE sepallength  NUMERIC\r\n   @ATTRIBUTE sepalwidth   NUMERIC\r\n   @ATTRIBUTE petallength  NUMERIC\r\n   @ATTRIBUTE petalwidth   NUMERIC\r\n   @ATTRIBUTE class        {Iris-setosa,Iris-versicolor,Iris-virginica}</pre>\r\n<p>ARFF failo duomenis aprašomi, kaip pavaizduota pavyzdyje:</p>\r\n<pre>   @DATA\r\n   5.1,3.5,1.4,0.2,Iris-setosa\r\n   4.9,3.0,1.4,0.2,Iris-setosa\r\n   4.7,3.2,1.3,0.2,Iris-setosa\r\n   4.6,3.1,1.5,0.2,Iris-setosa\r\n   5.0,3.6,1.4,0.2,Iris-setosa</pre>\r\n<p>Trūkstamos reikmės keičiamos klaustuko ženklu "?":</p>\r\n<pre>   @DATA\r\n   ?,3.5,?,0.2,Iris-setosa</pre>\r\n<h4>Kaip peržiūrėti eksperimentų rezultatus?</h4>\r\n<p>Norint peržiūrėti gautus eksperimentų rezultatus, į eksperimento užduočių seką reikia įkelti vieną iš trijų komponenčių:  </p>\r\n<ul>\r\n<li>„Techninė informacija“ – tai komponentė, skirta techninei informacijai peržiūrėti: skaičiavimo laikui, gautos paklaidos ir kt.</li>\r\n<li>„Matricinis vaizdavimas“ – tai komponentė, kurios pagalba naudotojas galės peržiūrėti duomenis ar algoritmų rezultatus matricos (lentelės) pavidalu, kai ši komponentė bus sujungta su failo įkėlimo ar algoritmo komponente.</li>\r\n<li>„Grafinis vaizdavimas“ – tai komponentė, kurios pagalba naudotojas galės peržiūrėti rezultatų grafiką, sujungus su vykdyto algoritmo komponente ir spragtelėjus ją du kartus. Atsidariusiame grafike naudotojas galės matyti grafiką.</li>\r\n</ul>\r\n<p>Naudotojas rezultatų peržiūros komponentes galės naudoti tik tuomet, kai bus apskaičiuoti eksperimento rezultatai.</p>\r\n<p>Komponentės „Grafinis vaizdavimas“ ir „Matricinis vaizdavimas“ turi galimybę atsiųsti rezultatus.</p>\r\n<h4>Kaip atlikti eksperimentą?</h4>\r\n<p>Norint atlikti eksperimentą su norima duomenų aibe, reikia sukurti norimą darbų seką ir ją įvykdyti. Tam reikia nutempti į eksperimento planavimo darbalaukį norimas komponentes, užpildyti reikiamų valdymo parametrų reikšmes, sujungti reikiamas komponentes ir paspausti mygtuką „vykdyti“. Tuomet atidaromas eksperimento vykdymo parametrų užpildymo langas. Užpildžius reikiamus laukus ir paspaudus mygtuką „Patvirtinti“, vyksta sekos patikrinimas: tikrinami kiekvienos komponentės įvesti valdymo parametrai ir kiekvienos komponentės sujungimas. Jei sekoje rastos klaidos, rodomas klaidos pranešimas prie nesujungtos komponentės arba pažymima raudonai ta komponentė, kurioje neteisingai įvesti valdymo parametrai. Priešingu atveju, jei komponentės sujungtos teisingai ir valdymo parametrai užpildyti tinkamai, tuomet eksperimentų istorijoje atsiranda naujas eksperimentas, kurio statusas „Vykdomas“.</p>\r\n<h4>Kaip sužinoti ar jau suformuoti eksperimento rezultatai?</h4>\r\n<p>Eksperimento planavimo lange sukūrus norimą darbų seką ir paspaudus mygtuką „Vykdyti“, eksperimentų istorijoje atsiranda naujas eksperimentas su nauju pavadinimu ir statusu „Vykdomas“. Kai eksperimentas įgauna statusą „Įvykdytas“, eksperimentų rezultatai bus prieinami peržiūrai.</p>\r\n<h4>Ar naudojantis DAMIS įrankiu galima analizuoti duomenų failą, kuriame yra praleistų reikšmių?</h4>\r\n<p>Jeigu duomenų failas turi praleistų reikšmių, tai norint jį analizuoti dimensijos mažinimo, klasifikavimo arba grupavimo metodais, duomenys turi būti išvalyti, prie duomenų įkėlimo komponentės prijungus  komponentę „Valymas“.</p>\r\n<h4>Pamiršau prisijungimo slaptažodį. Ką man daryti?</h4>\r\n<p>Pamiršus slaptažodį jį galima atstatyti. Prisijungimo lange paspauskite nuorodą „Pamiršau slaptažodį“, įveskite el. pašto adresą, kuriuo registravotės, ir sekite tolimesnius nurodymus.</p>\r\n<h4>Sėkmingai įvykdžius eksperimentą, noriu sužinoti algoritmo veikimo laiką. Kaip tai padaryti?</h4>\r\n<p>DAMIS yra realizuota galimybė peržiūrėti duomenų analizės algoritmo veikimo technines charakteristikas: veikimo laiką, gautą paklaidą ir kitas charakteristikas. Norint pamatyti šią informaciją prie duomenų analizės komponentės reikia prijungti komponentę „Techninė informacija“, esančią rezultatų peržiūros dalyje.</p>\r\n<p> </p>\r\n</div>', 4, '2014-03-18 09:30:03', '2014-07-07 14:16:52', 'lt'),
    (5, 'Pradinis puslapis', 'pradinis-puslapis', 'front_page', '<p>DAMIS.</p>', 1, '2014-04-29 13:22:16', '2014-05-08 14:38:40', 'lt'),
    (6, 'Front page', 'front-page', 'front_page', '<p>Hello</p>', 2, '2014-04-29 13:24:36', '2014-04-29 13:24:36', 'en');

-- ---------------------------------------------------------
-- Demo user (demo demo)
-- ---------------------------------------------------------

INSERT INTO `users` (`id`, `username`, `username_canonical`, `email`, `email_canonical`, `enabled`, `salt`, `password`, `last_login`, `locked`, `expired`, `expires_at`, `confirmation_token`, `password_requested_at`, `roles`, `credentials_expired`, `credentials_expire_at`, `registeredAt`, `name`, `surname`, `organisation`) VALUES
    (1, 'demo', 'demo', 'demo@demo.lt', 'demo@demo.lt', 1, '1vaf1uutuem8sk0w0gkgkgk4gwcgs0w', 'zod1RG6+fnCRNkzETBzRevAPdQOdXTjnkBQGYIvLMoi7jsudRmUBRfOInLiCoHYJSeooQ5ZUbeSdiuGzKplL+A==', '2014-10-03 14:47:34', 0, 0, NULL, NULL, NULL, 'a:2:{i:0;s:10:"ROLE_ADMIN";i:1;s:14:"ROLE_CONFIRMED";}', 0, NULL, '2014-04-02 11:16:08', 'Demo', 'Demo', NULL);
