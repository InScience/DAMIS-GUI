SET FOREIGN_KEY_CHECKS = 0;

INSERT INTO `cluster` (`ClusterName`, `ClusterWorkloadHost`, `ClusterDescription`, `ClusterID`, `ClusterUrl`, `WorkloadUrl`) VALUES
('MII Cluster', 'test', 'Distributed Computing cluster of Vilnius University Institute of Mathematics and Informatics', 1, 'http://hpc.mii.vu.lt/', 'http://hpc.mii.vu.lt/ganglia/'),
('MIF VU SK2', 'test', 'Supercomputer of Vilnius University Faculty of Mathematics and Informatics', 2,'http://mif.vu.lt/cluster/', 'http://k007.mif.vu.lt/ganglia2/');

INSERT INTO `componenttype` (`ComponentType`, `ComponentTypeID`) VALUES
('Upload data', 1),
('Preprocessing', 2),
('Statistical primitives', 3),
('Dimensionality reduction', 4),
('Classification, clustering', 5),
('View results', 6);

INSERT INTO `parameterconnectiontype` (`ParameterConnectionType`, `ParameterConnectionTypeID`) VALUES
('INPUT_CONNECTION', 1),
('OUTPUT_CONNECTION', 2),
('INPUT_VALUE', 3);

INSERT INTO `component` (`ComponentName`, `ComponentIcon`, `ComponentWSDLRunHost`, `ComponentWSDLCallFunction`, 
`ComponentDescription`, `ComponentAltDescription`, `ComponentLabelLT`, `ComponentLabelEN`, `ComponentID`, `FormType`, `ClusterID`, 
`ComponentTypeID`) VALUES
('Upload new file', 'upload-file-ico-1.jpeg', NULL, 'UPLOAD FILE', 'Upload file for data analysis', NULL, NULL, NULL, 1, 'NewFile', 1, 1),
('Upload new file', 'upload-file-ico-1.jpeg', NULL, 'UPLOAD FILE', 'Upload file for data analysis', NULL, NULL, NULL, 2, 'NewFile', 2, 1),
('Choose uploaded file', 'existing-file-ico.jpeg', NULL, 'EXISTING FILE', 'Select uploaded file', NULL, NULL, NULL, 3, 'UploadedFile', 1, 1),
('Choose uploaded file', 'existing-file-ico.jpeg', NULL, 'EXISTING FILE', 'Select uploaded file', NULL, NULL, NULL, 4, 'UploadedFile', 2, 1),
('Upload file from MIDAS', 'midas-file.jpeg', NULL, 'MIDAS FILE', 'Select file from MIDAS archive', NULL, NULL, NULL, 5, 'MidasFile', 1, 1),
('Upload file from MIDAS', 'midas-file.jpeg', NULL, 'MIDAS FILE', 'Select file from MIDAS archive', NULL, NULL, NULL, 6, 'MidasFile', 2, 1),
('Clean data', 'clean-data-ico.jpeg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'CLEANDATA', 'Data cleaning', NULL, NULL, NULL, 7, 'NoForm', 1, 2),
('Clean data', 'clean-data-ico.jpeg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'CLEANDATA', 'Data cleaning', NULL, NULL, NULL, 8, 'NoForm', 2, 2),
('Filter data', 'filter-data-ico.jpeg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'FILTERDATA', 'Filter data description', NULL, NULL, NULL, 9, 'Filter', 1, 2),
('Filter data', 'filter-data-ico.jpeg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'FILTERDATA', 'Filter data description', NULL, NULL, NULL, 10, 'Filter', 2, 2),
('Split data', 'split-data-ico.jpeg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'SPLITDATA', 'Split a file into given number of parts', NULL, NULL, NULL, 11, 'SplitData', 1, 2),
('Split data', 'split-data-ico.jpeg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'SPLITDATA', 'Split a file into given number of parts', NULL, NULL, NULL, 12, 'SplitData', 2, 2),
('Transpose data', 'transpose-data-ico.jpeg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'TRANSPOSEDATA', 'Transpose (rotate) data from rows to columns or vice versa', NULL, NULL, NULL, 13, 'NoForm', 1, 2),
('Transpose data', 'transpose-data-ico.jpeg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'TRANSPOSEDATA', 'Transpose (rotate) data from rows to columns or vice versa', NULL, NULL, NULL, 14, 'NoForm', 2, 2),
('Norm data', 'transform-data-ico.jpeg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'NORMDATA', 'Data transformation', NULL, NULL, NULL, 15, 'NormData', 1, 2),
('Norm data', 'transform-data-ico.jpeg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'NORMDATA', 'Data transformation', NULL, NULL, NULL, 16, 'NormData', 2, 2),
('Feature selection', 'select-ico.jpeg', NULL, 'SELECT', 'Select features', NULL, NULL, NULL, 17, 'Select', 1, 2),
('Feature selection', 'select-ico.jpeg', NULL, 'SELECT', 'Select features', NULL, NULL, NULL, 18, 'Select', 2, 2),
('Statistical data', 'statistical-primitives-icon.jpeg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'STATPRIMITIVES', 'The set of statistical primitives', NULL, NULL, NULL, 19, 'NoForm', 1, 3),
('Statistical data', 'statistical-primitives-icon.jpeg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'STATPRIMITIVES', 'The set of statistical primitives', NULL, NULL, NULL, 20, 'NoForm', 2, 3),
('PCA', 'dimensionality-reduction-ico.jpg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'PCA', 'Principal Component Analysis', NULL, NULL, NULL, 21, 'Pca', 1, 4),
('PCA', 'dimensionality-reduction-ico.jpg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'PCA', 'Principal Component Analysis', NULL, NULL, NULL, 22, 'Pca', 2, 4),
('SMACOF (MDS)', 'dimensionality-reduction-ico.jpg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'SMACOFMDS', 'SMACOF (MDS) algorithm', NULL, NULL, NULL, 23, 'Smacof', 1, 4),
('SMACOF (MDS)', 'dimensionality-reduction-ico.jpg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'SMACOFMDS', 'SMACOF (MDS) algorithm', NULL, NULL, NULL, 24, 'Smacof', 2, 4),
('DMA', 'dimensionality-reduction-ico.jpg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'DMA', 'Diagonal majorization algorithm', NULL, NULL, NULL, 25, 'Dma', 1, 4),
('DMA', 'dimensionality-reduction-ico.jpg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'DMA', 'Diagonal majorization algorithm', NULL, NULL, NULL, 26, 'Dma', 2, 4),
('Relative MDS', 'dimensionality-reduction-ico.jpg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'RELMDS', 'Relative Multidimensional Scaling (MDS)  algorithm', NULL, NULL, NULL, 27, 'RelativeMds', 1, 4),
('Relative MDS', 'dimensionality-reduction-ico.jpg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'RELMDS', 'Relative Multidimensional Scaling (MDS)  algorithm', NULL, NULL, NULL, 28, 'RelativeMds', 2, 4),
('SAMANN', 'dimensionality-reduction-ico.jpg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'SAMANN', 'SAMANN algorithm', NULL, NULL, NULL, 29, 'Samann', 1, 4),
('SAMANN', 'dimensionality-reduction-ico.jpg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'SAMANN', 'SAMANN algorithm', NULL, NULL, NULL, 30, 'Samann', 2, 4),
('SOM-MDS', 'dimensionality-reduction-ico.jpg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'SOMMDS', 'SOM for Multidimensional Data Visualization', NULL, NULL, NULL, 31, 'SomMds', 1, 4),
('SOM-MDS', 'dimensionality-reduction-ico.jpg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'SOMMDS', 'SOM for Multidimensional Data Visualization', NULL, NULL, NULL, 32, 'SomMds', 2, 4),
('SOM', 'som-ico.jpeg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'SOM', 'Self-Organizing Map (SOM)', NULL, NULL, NULL, 33, 'Som', 1, 5),
('SOM', 'som-ico.jpeg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'SOM', 'Self-Organizing Map (SOM)', NULL, NULL, NULL, 34, 'Som', 2, 5),
('MLP', 'mlp-ico.jpeg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'MLP', 'Multilayer perceptron', NULL, NULL, NULL, 35, 'Mlp', 1, 5),
('MLP', 'mlp-ico.jpeg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'MLP', 'Multilayer perceptron', NULL, NULL, NULL, 36, 'Mlp', 2, 5),
('RDF', 'RDF-ico.jpeg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'DF', 'RDF classifier', NULL, NULL, NULL, 37, 'Rdf', 1, 5),
('RDF', 'RDF-ico.jpeg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'DF', 'RDF classifier', NULL, NULL, NULL, 38, 'Rdf', 2, 5),
('K-MEANS', 'kmeans-ico.jpeg', 'http://158.129.140.134:8087/cgi-bin/DamisService.cgi?wsdl', 'KMEANS', 'k-means clustering', NULL, NULL, NULL, 39, 'Kmeans', 1, 5),
('K-MEANS', 'kmeans-ico.jpeg', 'http://damis.lt:8087/cgi-bin/DamisService.cgi?wsdl', 'KMEANS', 'k-means clustering', NULL, NULL, NULL, 40, 'Kmeans', 2, 5),
('Technical details', 'technical-details-ico.jpeg', NULL, 'TECHNICALINFO', 'Show all component''s outputs'' values', NULL, NULL, NULL, 41, 'TechnicalInfo', 1, 6),
('Technical details', 'technical-details-ico.jpeg', NULL, 'TECHNICALINFO', 'Show all component''s outputs'' values', NULL, NULL, NULL, 42, 'TechnicalInfo', 2, 6),
('Matrix view', 'matrix-view-ico.jpeg', NULL, 'MATRIX', 'Results matrix view', NULL, NULL, NULL, 43, 'Matrix', 1, 6),
('Matrix view', 'matrix-view-ico.jpeg', NULL, 'MATRIX', 'Results matrix view', NULL, NULL, NULL, 44, 'Matrix', 2, 6),
('Chart view', 'chart-ico.jpeg', NULL, 'CHART', 'Chart', NULL, NULL, NULL, 45, 'Chart', 1, 6),
('Chart view', 'chart-ico.jpeg', NULL, 'CHART', 'Chart', NULL, NULL, NULL, 46, 'Chart', 2, 6);


INSERT INTO `parameter` (`ParameterName`, `ParameterIsRequired`, `ParameterDefault`, `ParameterDescription`, 
                         `ParameterLabelLT`, `ParameterLabelEN`, `ParameterID`, `ParameterSlug`, `ParameterPosition`,
                         `ParameterTypeID`, `ParameterConnectionTypeID`, `ComponentID`) VALUES
('dataset', 0, NULL, NULL, NULL, NULL, 1, 'Y', NULL, NULL, 2, 1),
('dataset', 0, NULL, NULL, NULL, NULL, 2, 'Y', NULL, NULL, 2, 2),
('X', 0, NULL, NULL, NULL, NULL, 3, 'X', NULL, NULL, 1, 9),
('Y', 0, NULL, NULL, NULL, NULL, 4, 'Y', NULL, NULL, 2, 9),
('X', 0, NULL, NULL, NULL, NULL, 5, 'X', NULL, NULL, 1, 10),
('Y', 0, NULL, NULL, NULL, NULL, 6, 'Y', NULL, NULL, 2, 10),
('Result type', 1, NULL, NULL, NULL, NULL, 9, 'retFilteredData', 1, NULL, 3, 9),
('Z value', 1, NULL, NULL, NULL, NULL, 10, 'zValue', 2, NULL, 3, 9),
('Attribute', 1, NULL, NULL, NULL, NULL, 11, 'attrIndex', 3, NULL, 3, 9),
('Result type', 1, NULL, NULL, NULL, NULL, 12, 'retFilteredData', 1, NULL, 3, 10),
('Z value', 1, NULL, NULL, NULL, NULL, 13, 'zValue', 2, NULL, 3, 10),
('Attribute', 1, NULL, NULL, NULL, NULL, 14, 'attrIndex', 3, NULL, 3, 10),
('Maximum number of iteartion', 1, NULL, NULL, NULL, NULL, 15, 'maxIteration', 5, NULL, 3, 35),
('1st layer', 1, NULL, NULL, NULL, NULL, 16, 'h1pNo', 1, NULL, 3, 35),
('2nd layer', 1, NULL, NULL, NULL, NULL, 17, 'h2pNo', 2, NULL, 3, 35),
('Training type selection parameter', 1, NULL, NULL, NULL, NULL, 18, 'kFoldValidation', 4, NULL, 3, 35),
('Size of training data/Cross validation k', 1, NULL, NULL, NULL, NULL, 19, 'qty', 3, NULL, 3, 35),
('X', 0, NULL, NULL, NULL, NULL, 22, 'X', NULL, NULL, 1, 35),
('Y', 0, NULL, NULL, NULL, NULL, 23, 'Y', NULL, NULL, 2, 35),
('Maximum number of iteartion', 1, NULL, NULL, NULL, NULL, 24, 'maxIteration', 5, NULL, 3, 36),
('1st layer', 1, NULL, NULL, NULL, NULL, 25, 'h1pNo', 1, NULL, 3, 36),
('2nd layer', 1, NULL, NULL, NULL, NULL, 26, 'h2pNo', 2, NULL, 3, 36),
('Training type selection parameter', 1, NULL, NULL, NULL, NULL, 27, 'kFoldValidation', 4, NULL, 3, 36),
('Size of training data/Cross validation k', 1, NULL, NULL, NULL, NULL, 28, 'qty', 3, NULL, 3, 36),
('X', 0, NULL, NULL, NULL, NULL, 31, 'X', NULL, NULL, 1, 36),
('Y', 0, NULL, NULL, NULL, NULL, 32, 'Y', NULL, NULL, 2, 36),
('dataset', 0, NULL, NULL, NULL, NULL, 33, 'Y', NULL, NULL, 2, 5),
('dataset', 0, NULL, NULL, NULL, NULL, 34, 'Y', NULL, NULL, 2, 6),
('Number of rows of SOM', 1, NULL, NULL, NULL, NULL, 35, 'rows', 1, NULL, 3, 31),
('Number of columns of SOM', 1, NULL, NULL, NULL, NULL, 36, 'columns', 2, NULL, 3, 31),
('Number of SOM training epochs', 1, NULL, NULL, NULL, NULL, 37, 'eHat', 3, NULL, 3, 31),
('Projection space of MDS', 1, NULL, NULL, NULL, NULL, 38, 'mdsProjection', 6, NULL, 3, 31),
('Number of iterations of MDS', 1, NULL, NULL, NULL, NULL, 39, 'mdsIteration', 4, NULL, 3, 31),
('Minimal stress change', 1, NULL, NULL, NULL, NULL, 40, 'eps', 5, NULL, 3, 31),
('Number of rows of SOM', 1, NULL, NULL, NULL, NULL, 41, 'rows', 1, NULL, 3, 32),
('Number of columns of SOM', 1, NULL, NULL, NULL, NULL, 42, 'columns', 2, NULL, 3, 32),
('Number of SOM training epochs', 1, NULL, NULL, NULL, NULL, 43, 'eHat', 3, NULL, 3, 32),
('Projection space of MDS', 1, NULL, NULL, NULL, NULL, 44, 'mdsProjection', 6, NULL, 3, 32),
('Number of iterations of MDS', 1, NULL, NULL, NULL, NULL, 45, 'mdsIteration', 4, NULL, 3, 32),
('Minimal stress change', 1, NULL, NULL, NULL, NULL, 46, 'eps', 5, NULL, 3, 32),
('X', 0, NULL, NULL, NULL, NULL, 47, 'X', NULL, NULL, 1, 31),
('Y', 0, NULL, NULL, NULL, NULL, 48, 'Y', NULL, NULL, 2, 31),
('X', 0, NULL, NULL, NULL, NULL, 49, 'X', NULL, NULL, 1, 32),
('Y', 0, NULL, NULL, NULL, NULL, 50, 'Y', NULL, NULL, 2, 32),
('X', 0, NULL, NULL, NULL, NULL, 51, 'X', NULL, NULL, 1, 27),
('Y', 0, NULL, NULL, NULL, NULL, 52, 'Y', NULL, NULL, 2, 27),
('X', 0, NULL, NULL, NULL, NULL, 53, 'X', NULL, NULL, 1, 28),
('Y', 0, NULL, NULL, NULL, NULL, 54, 'Y', NULL, NULL, 2, 28),
('Projection space', 1, NULL, NULL, NULL, NULL, 55, 'd', 1, NULL, 3, 27),
('Maximum number of iteration', 1, NULL, NULL, NULL, NULL, 56, 'maxIteration', 2, NULL, 3, 27),
('Minimal stress change', 1, NULL, NULL, NULL, NULL, 57, 'eps', 3, NULL, 3, 27),
('Relative number of basis objects', 1, NULL, NULL, NULL, NULL, 58, 'noOfBaseVectors', 4, NULL, 3, 27),
('Select Basis objects strategy', 1, NULL, NULL, NULL, NULL, 59, 'selStrategy', 5, NULL, 3, 27),
('Projection space', 1, NULL, NULL, NULL, NULL, 60, 'd', 1, NULL, 3, 28),
('Maximum number of iteration', 1, NULL, NULL, NULL, NULL, 61, 'maxIteration', 2, NULL, 3, 28),
('Minimal stress change', 1, NULL, NULL, NULL, NULL, 62, 'eps', 3, NULL, 3, 28),
('Relative number of basis objects', 1, NULL, NULL, NULL, NULL, 63, 'noOfBaseVectors', 4, NULL, 3, 28),
('Select Basis objects strategy', 1, NULL, NULL, NULL, NULL, 64, 'selStrategy', 5, NULL, 3, 28),
('X', 0, NULL, NULL, NULL, NULL, 65, 'X', NULL, NULL, 1, 7),
('Y', 0, NULL, NULL, NULL, NULL, 66, 'Y', NULL, NULL, 2, 7),
('X', 0, NULL, NULL, NULL, NULL, 67, 'X', NULL, NULL, 1, 8),
('Y', 0, NULL, NULL, NULL, NULL, 68, 'Y', NULL, NULL, 2, 8),
('X', 0, NULL, NULL, NULL, NULL, 69, 'X', NULL, NULL, 1, 45),
('X', 0, NULL, NULL, NULL, NULL, 70, 'X', NULL, NULL, 1, 46),
('dataset', 0, NULL, NULL, NULL, NULL, 71, 'Y', NULL, NULL, 2, 3),
('dataset', 0, NULL, NULL, NULL, NULL, 72, 'Y', NULL, NULL, 2, 4),
('X', 0, NULL, NULL, NULL, NULL, 73, 'X', NULL, NULL, 1, 21),
('Y', 0, NULL, NULL, NULL, NULL, 74, 'Y', NULL, NULL, 2, 21),
('X', 0, NULL, NULL, NULL, NULL, 75, 'X', NULL, NULL, 1, 22),
('Y', 0, NULL, NULL, NULL, NULL, 76, 'Y', NULL, NULL, 2, 22),
('Choose PCA projection', 1, NULL, NULL, NULL, NULL, 77, 'projType', 1, NULL, 3, 21),
('Space/Variance', 1, NULL, NULL, NULL, NULL, 78, 'd', 2, NULL, 3, 21),
('Choose PCA projection', 1, NULL, NULL, NULL, NULL, 79, 'projType', 1, NULL, 3, 22),
('Space/Variance', 1, NULL, NULL, NULL, NULL, 80, 'd', 2, NULL, 3, 22),
('X', 0, NULL, NULL, NULL, NULL, 81, 'X', NULL, NULL, 1, 25),
('Y', 0, NULL, NULL, NULL, NULL, 82, 'Y', NULL, NULL, 2, 25),
('X', 0, NULL, NULL, NULL, NULL, 83, 'X', NULL, NULL, 1, 26),
('Y', 0, NULL, NULL, NULL, NULL, 84, 'Y', NULL, NULL, 2, 26),
('Projection space', 1, NULL, NULL, NULL, NULL, 85, 'd', 1, NULL, 3, 25),
('Maximum number of iteration', 1, NULL, NULL, NULL, NULL, 86, 'maxIteration', 2, NULL, 3, 25),
('Minimal stress change', 1, NULL, NULL, NULL, NULL, 87, 'eps', 3, NULL, 3, 25),
('Relative number of neighbours', 1, NULL, NULL, NULL, NULL, 88, 'neighbour', 4, NULL, 3, 25),
('Projection space', 1, NULL, NULL, NULL, NULL, 89, 'd', 1, NULL, 3, 26),
('Maximum number of iteration', 1, NULL, NULL, NULL, NULL, 90, 'maxIteration', 2, NULL, 3, 26),
('Minimal stress change', 1, NULL, NULL, NULL, NULL, 91, 'eps', 3, NULL, 3, 26),
('Relative number of neighbours', 1, NULL, NULL, NULL, NULL, 92, 'neighbour', 4, NULL, 3, 26),
('X', 0, NULL, NULL, NULL, NULL, 93, 'X', NULL, NULL, 1, 39),
('Y', 0, NULL, NULL, NULL, NULL, 94, 'Y', NULL, NULL, 2, 39),
('X', 0, NULL, NULL, NULL, NULL, 95, 'X', NULL, NULL, 1, 40),
('Y', 0, NULL, NULL, NULL, NULL, 96, 'Y', NULL, NULL, 2, 40),
('Maximum number of cluster', 1, NULL, NULL, NULL, NULL, 97, 'kMax', 1, NULL, 3, 39),
('Maximum number of iteration', 1, NULL, NULL, NULL, NULL, 98, 'maxIteration', 2, NULL, 3, 39),
('Maximum number of cluster', 1, NULL, NULL, NULL, NULL, 99, 'kMax', 1, NULL, 3, 40),
('Maximum number of iteration', 1, NULL, NULL, NULL, NULL, 100, 'maxIteration', 2, NULL, 3, 40),
('X', 0, NULL, NULL, NULL, NULL, 101, 'X', NULL, NULL, 1, 13),
('Y', 0, NULL, NULL, NULL, NULL, 102, 'Y', NULL, NULL, 2, 13),
('X', 0, NULL, NULL, NULL, NULL, 103, 'X', NULL, NULL, 1, 14),
('Y', 0, NULL, NULL, NULL, NULL, 104, 'Y', NULL, NULL, 2, 14),
('X', 0, NULL, NULL, NULL, NULL, 105, 'X', NULL, NULL, 1, 11),
('Y', 0, NULL, NULL, NULL, NULL, 106, 'Y', NULL, NULL, 2, 11),
('X', 0, NULL, NULL, NULL, NULL, 107, 'X', NULL, NULL, 1, 12),
('Y', 0, NULL, NULL, NULL, NULL, 108, 'Y', NULL, NULL, 2, 12),
('Choose object sort type', 1, NULL, NULL, NULL, NULL, 109, 'reshufleObjects', 1, NULL, 3, 11),
('First subset size', 1, NULL, NULL, NULL, NULL, 110, 'firstSubsetPerc', 2, NULL, 3, 11),
('Second subset size', 1, NULL, NULL, NULL, NULL, 111, 'secondSubsetPerc', 3, NULL, 3, 11),
('Choose object sort type', 1, NULL, NULL, NULL, NULL, 112, 'reshufleObjects', 1, NULL, 3, 12),
('First subset size', 1, NULL, NULL, NULL, NULL, 113, 'firstSubsetPerc', 2, NULL, 3, 12),
('Second subset size', 1, NULL, NULL, NULL, NULL, 114, 'secondSubsetPerc', 3, NULL, 3, 12),
('X', 0, NULL, NULL, NULL, NULL, 115, 'X', NULL, NULL, 1, 19),
('Y', 0, NULL, NULL, NULL, NULL, 116, 'Y', NULL, NULL, 2, 19),
('X', 0, NULL, NULL, NULL, NULL, 117, 'X', NULL, NULL, 1, 20),
('Y', 0, NULL, NULL, NULL, NULL, 118, 'Y', NULL, NULL, 2, 20),
('X', 0, NULL, NULL, NULL, NULL, 119, 'X', NULL, NULL, 1, 15),
('Y', 0, NULL, NULL, NULL, NULL, 120, 'Y', NULL, NULL, 2, 15),
('X', 0, NULL, NULL, NULL, NULL, 121, 'X', NULL, NULL, 1, 16),
('Y', 0, NULL, NULL, NULL, NULL, 122, 'Y', NULL, NULL, 2, 16),
('Choose norm method', 1, NULL, NULL, NULL, NULL, 123, 'normMeanStd', 1, NULL, 3, 15),
('a', 1, NULL, NULL, NULL, NULL, 124, 'a', 2, NULL, 3, 15),
('b', 1, NULL, NULL, NULL, NULL, 125, 'b', 3, NULL, 3, 15),
('Choose norm method', 1, NULL, NULL, NULL, NULL, 126, 'normMeanStd', 1, NULL, 3, 16),
('a', 1, NULL, NULL, NULL, NULL, 127, 'a', 2, NULL, 3, 16),
('b', 1, NULL, NULL, NULL, NULL, 128, 'b', 3, NULL, 3, 16),
('X', 0, NULL, NULL, NULL, NULL, 129, 'X', NULL, NULL, 1, 23),
('Y', 0, NULL, NULL, NULL, NULL, 130, 'Y', NULL, NULL, 2, 23),
('X', 0, NULL, NULL, NULL, NULL, 131, 'X', NULL, NULL, 1, 24),
('Y', 0, NULL, NULL, NULL, NULL, 132, 'Y', NULL, NULL, 2, 24),
('Projection space', 1, NULL, NULL, NULL, NULL, 133, 'd', 1, NULL, 3, 23),
('Maximum number of iteration', 1, NULL, NULL, NULL, NULL, 134, 'maxIteration', 2, NULL, 3, 23),
('Minimal stress change', 1, NULL, NULL, NULL, NULL, 135, 'eps', 3, NULL, 3, 23),
('Does apply Seidel modification?', 1, NULL, NULL, NULL, NULL, 136, 'zeidel', 4, NULL, 3, 23),
('Projection space', 1, NULL, NULL, NULL, NULL, 137, 'd', 1, NULL, 3, 24),
('Maximum number of iteration', 1, NULL, NULL, NULL, NULL, 138, 'maxIteration', 2, NULL, 3, 24),
('Minimal stress change', 1, NULL, NULL, NULL, NULL, 139, 'eps', 3, NULL, 3, 24),
('Does apply Seidel modification?', 1, NULL, NULL, NULL, NULL, 140, 'zeidel', 4, NULL, 3, 24),
('X', 0, NULL, NULL, NULL, NULL, 141, 'X', NULL, NULL, 1, 29),
('Y', 0, NULL, NULL, NULL, NULL, 142, 'Y', NULL, NULL, 2, 29),
('X', 0, NULL, NULL, NULL, NULL, 143, 'X', NULL, NULL, 1, 30),
('Y', 0, NULL, NULL, NULL, NULL, 144, 'Y', NULL, NULL, 2, 30),
('Projection space', 1, NULL, NULL, NULL, NULL, 145, 'd', 1, NULL, 3, 29),
('Maximum number of iteration', 1, NULL, NULL, NULL, NULL, 146, 'maxIteration', 2, NULL, 3, 29),
('Relative size of the training data', 1, NULL, NULL, NULL, NULL, 147, 'mTrain', 3, NULL, 3, 29),
('Number of neurons in the hidden layer', 1, NULL, NULL, NULL, NULL, 148, 'nNeurons', 4, NULL, 3, 29),
('Value of the learning rate', 1, NULL, NULL, NULL, NULL, 149, 'eta', 5, NULL, 3, 29),
('Projection space', 1, NULL, NULL, NULL, NULL, 150, 'd', 1, NULL, 3, 30),
('Maximum number of iteration', 1, NULL, NULL, NULL, NULL, 151, 'maxIteration', 2, NULL, 3, 30),
('Relative size of the training data', 1, NULL, NULL, NULL, NULL, 152, 'mTrain', 3, NULL, 3, 30),
('Number of neurons in the hidden layer', 1, NULL, NULL, NULL, NULL, 153, 'nNeurons', 4, NULL, 3, 30),
('Value of the learning rate', 1, NULL, NULL, NULL, NULL, 154, 'eta', 5, NULL, 3, 30),
('X', 0, NULL, NULL, NULL, NULL, 155, 'X', NULL, NULL, 1, 33),
('Y', 0, NULL, NULL, NULL, NULL, 156, 'Y', NULL, NULL, 2, 33),
('X', 0, NULL, NULL, NULL, NULL, 157, 'X', NULL, NULL, 1, 34),
('Y', 0, NULL, NULL, NULL, NULL, 158, 'Y', NULL, NULL, 2, 34),
('Number of rows', 1, NULL, NULL, NULL, NULL, 159, 'rows', 1, NULL, 3, 33),
('Number of columns', 1, NULL, NULL, NULL, NULL, 160, 'columns', 2, NULL, 3, 33),
('Number of training epochs', 1, NULL, NULL, NULL, NULL, 161, 'eHat', 3, NULL, 3, 33),
('Number of rows', 1, NULL, NULL, NULL, NULL, 162, 'rows', 1, NULL, 3, 34),
('Number of columns', 1, NULL, NULL, NULL, NULL, 163, 'columns', 2, NULL, 3, 34),
('Number of training epochs', 1, NULL, NULL, NULL, NULL, 164, 'eHat', 3, NULL, 3, 34),
('X', 0, NULL, NULL, NULL, NULL, 165, 'X', NULL, NULL, 1, 37),
('Y', 0, NULL, NULL, NULL, NULL, 166, 'Y', NULL, NULL, 2, 37),
('X', 0, NULL, NULL, NULL, NULL, 167, 'X', NULL, NULL, 1, 38),
('Y', 0, NULL, NULL, NULL, NULL, 168, 'Y', NULL, NULL, 2, 38),
('Confidence level', 1, NULL, NULL, NULL, NULL, 169, 'q', 1, NULL, 3, 37),
('Size of training data', 1, NULL, NULL, NULL, NULL, 170, 'dL', 2, NULL, 3, 37),
('Size of test data', 1, NULL, NULL, NULL, NULL, 171, 'dT', 3, NULL, 3, 37),
('Confidence level', 1, NULL, NULL, NULL, NULL, 172, 'q', 1, NULL, 3, 38),
('Size of training data', 1, NULL, NULL, NULL, NULL, 173, 'dL', 2, NULL, 3, 38),
('Size of test data', 1, NULL, NULL, NULL, NULL, 174, 'dT', 3, NULL, 3, 38),
('X', 0, NULL, NULL, NULL, NULL, 175, 'X', NULL, NULL, 1, 43),
('X', 0, NULL, NULL, NULL, NULL, 176, 'X', NULL, NULL, 1, 44),
('X', 0, NULL, NULL, NULL, NULL, 177, 'X', NULL, NULL, 1, 41),
('X', 0, NULL, NULL, NULL, NULL, 178, 'X', NULL, NULL, 1, 42),
('X', 0, NULL, NULL, NULL, NULL, 179, 'X', NULL, NULL, 1, 17),
('Y', 0, NULL, NULL, NULL, NULL, 180, 'Y', NULL, NULL, 2, 17),
('X', 0, NULL, NULL, NULL, NULL, 181, 'X', NULL, NULL, 1, 18),
('Y', 0, NULL, NULL, NULL, NULL, 182, 'Y', NULL, NULL, 2, 18),
('Attributes', 1, NULL, NULL, NULL, NULL, 183, 'attr', 1, NULL, 3, 17),
('Selected attributes', 1, NULL, NULL, NULL, NULL, 184, 'selAttr', 2, NULL, 3, 17),
('Class attribute', 1, NULL, NULL, NULL, NULL, 185, 'classAttr', 3, NULL, 3, 17),
('Attributes', 1, NULL, NULL, NULL, NULL, 186, 'attr', 1, NULL, 3, 18),
('Selected attributes', 1, NULL, NULL, NULL, NULL, 187, 'selAttr', 2, NULL, 3, 18),
('Class attribute', 1, NULL, NULL, NULL, NULL, 188, 'classAttr', 3, NULL, 3, 18),
('Yalt', 0, NULL, NULL, NULL, NULL, 189, 'Yalt', NULL, NULL, 2, 11),
('Yalt', 0, NULL, NULL, NULL, NULL, 190, 'Yalt', NULL, NULL, 2, 12);


INSERT INTO `experimentstatus` (`ExperimentStatus`, `ExperimentStatusID`) VALUES
	('SAVED', 1),
	('EXECUTING', 2),
	('FINISHED', 3),
	('ERROR', 4),
    ('SUSPENDED', 5),
    ('EXAMPLE', 6);

-- --------------------------------------------------------
-- help pages
-- --------------------------------------------------------

INSERT INTO `page` (`id`, `title`, `slug`, `groupName`, `text`, `position`, `created`, `updated`, `language`) VALUES
    (1, 'Help', 'help', 'help', '<h2>Uploading of data</h2>\r\n<h3>Upload file</h3>\r\n<p>Upload data file. It is possible to upload data table from a supported file formats: tab, txt, csv, ARFF and XML files, which are compressed in zip format.</p>\r\n<p>Requirements for data file: A dataset is roughly equivalent to a two-dimensional spreadsheet or database table. A dataset is a collection of instances, where each instance consists of a number of attributes. The external representation of an Instances class is an ARFF file, which consists of a header describing the attribute types and the data as comma-separated list.</p>\r\n<h3>Existing file</h3>\r\n<p>Open a set of instances from DAMIS data base.</p>\r\n<h3>MIDAS file</h3>\r\n<p>Open a set of instances from MIDAS data base</p>\r\n<h2>Preprocessing</h2>\r\n<h3>Cleaning | Cleaning data</h3>\r\n<p>Cleaning data reduces errors and improves the data quality for further data analysis. After reading the ARFF file, data section checking is initiated. Each data section attribute is checked whether its data type conforms the type declared in attribute section if not then error message is sent to the user. Also it is checked the missing data. At the moment if missing object data is found, then this object will be eliminated from the further calculations. In this way it isensured that all data records will have values and are suitable for further analysis.</p>\r\n<h4><strong>Parameters:</strong></h4>\r\n<p>This component does not have control parameters.</p>\r\n<h3>Filtering | Filter data</h3>\r\n<p>Filtering removes instances from dataset that meet a particular criterion. These instances are called outliers, i.e.the data instances which are significantly different from the remaining data. Result of filtering should be either the analyzed data set without outliers, or only outliers. Filtering is performed according to a selected attribute and the threshold of Z value (quintile). It is recommended to use Z value greater than 3.0.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<ul>\r\n<li><strong>Choose filtering results</strong> – without outliers, only outliers.</li>\r\n<li><strong>Z value – </strong>valid Z value is positive real number.</li>\r\n<li><strong>Attribute</strong> – set the selected attribute for outlier filtering</li>\r\n</ul>\r\n<h3>Split data | Splitting of initial data set into two smaller subsets</h3>\r\n<p>Split data – splitting of initial data set into two smaller subsets. Two obtained subsets could be analysed by parallel or analysed one of them, for example, subset of instances could be represented regularities of all population.</p>\r\n<p>Splitting ways of the initial data set:</p>\r\n<ol>\r\n<li>Order of initial data instances is unchanged and splitting of initial data set into two smaller subsets is done according to values of splitting parameters.</li>\r\n<li>Instances of initial data set are mixed at random and splitting of initial data set into two smaller subsets is done according to values of splitting parameters.</li>\r\n</ol>\r\n<p><strong>Parameters:</strong></p>\r\n<ul>\r\n<li><strong><strong>Choose object sort type<strong> – Order left intact</strong></strong></strong> (Order of initial data instances is unchanged);<strong><strong> Random </strong></strong>(Instances of initial data set are mixed at random).</li>\r\n<li>\r\n<p><strong>First subset size<strong> –</strong></strong> Sets the relative (percentage) size of the first subset from the initial data set.</p>\r\n</li>\r\n<li>\r\n<p><strong>Second subset size<strong> –</strong></strong> Size of second subset is calculated automatically by formula (100 %- First subset size).</p>\r\n</li>\r\n</ul>\r\n<h3>Transpose data</h3>\r\n<p>Transpose (rotate) data from rows to columns or vice versa.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<p>This component does not have control parameters.<br /><br /></p>\r\n<h3>Norm data | Data Transformation by Normalization</h3>\r\n<p>The measurement unit used can affect the data analysis. To help avoid dependence on the choice of measurement units, the data should be normalized or standardized. This involves transforming the data to fall within a smaller or common range. Normalizing the data attempts to give all attributes an equal weight. Two methods for data normalization could be used:</p>\r\n<ol>\r\n<li>The values for an each attribute are normalized based on the mean (i.e., average) and standard deviation. Default values: means equal 0, standard deviation equal 1.</li>\r\n<li>Min-max normalization performs a linear transformation on the original data. Min-max normalization maps a original value of each attribute to a new value in the interval [a, b].</li>\r\n</ol>\r\n<p><strong>Parameters:</strong></p>\r\n<ul>\r\n<li><strong>Mean a, standard deviation b </strong>– the values for an each attribute are normalized based on the mean (i.e., average) (parameter a) and standard deviation (parameter b). Default values: mean a=0, standard deviation b=1.</li>\r\n<li><strong>Interval [a; b] – </strong>Min-max normalization maps a original value of each attribute to a new value in the interval [a, b]. Default values: a=0, b=1, interval upper bound must be greater than lower.</li>\r\n</ul>\r\n<h3>Feature selection</h3>\r\n<p>Feature selection component is used to manually compose new analyzed data domain. It is possible to decide which attributes will be used and how. For instance, for building a classification model, the domain would be composed of a set of attributes and a class attribute, which is also selected from a set of attributes. The attributes are included in the data set but are, for most of the methods, not considered in data analysis.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<ul>\r\n<li><strong>Selected attributes – </strong><strong>selected data attributes in the new data file. </strong>Default value – empty list.</li>\r\n<li><strong>Class attribute<strong> - </strong></strong>A class attribute is selected from all attributes list of initial data set. Default value – empty or none. If none, the new data set will be classless.</li>\r\n</ul>\r\n<h2>Statistical primitives</h2>\r\n<h3>Statistical data| Calculation of statistical primitives</h3>\r\n<p>Calculation of statistical primitives: min, max, mean, standard deviation, median.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<p>This component does not have control parameters.</p>\r\n<h2>Dimension reduction</h2>\r\n<h3>PCA – principal component analysis</h3>\r\n<p>PCA is a standard technique for visualizing high dimensional data and for data pre-processing. PCA reduces the dimensionality (the number of variables) of a data set by maintaining as much variance as possible.</p>\r\n<p>Principal component analysis (PCA) rotates the original data space such that the axes of the new coordinate system point into the directions of highest variance of the data. The axes or new variables are termed principal components (PCs) and are ordered by variance: The first component represents the direction of the highest variance of the data. The direction of the second component represents the highest of the remaining variance orthogonal to the first component. This can be naturally extended to obtain the required number of components which together span a component space covering the desired amount of variance. Since components describe specific directions in the data space, each component depends by certain amounts on each of the original variables: Each component is a linear combination of all original variables.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<ul>\r\n<li><strong>Space</strong> – low-dimensional space or projection space; positive integer value, space dimension cannot be greater than quantity of attributes in analysed file, default value 2.</li>\r\n<li><strong>Attribute relative cumulative variance</strong> – the amount of variance, which must be preserved. Relative cumulative variance must be in interval (0; 100]%.</li>\r\n</ul>\r\n<h3>MDS SMACOF | Multidimensional scaling (MDS) SMACOF algorithm</h3>\r\n<p>The multidimensional scaling (MDS) is a group of methods that project multidimensional data to a low (usually two) dimensional space and preserve the interpoint distances among data as much as possible. The goal of multidimensional scaling is to find low-dimensional points, such that the distances between he points in the low-dimensional space were as close to the proximities as possible.</p>\r\n<p>The MDS Stress function can be minimized using SMACOF algorithm. SMACOF algorithm is based on iterative majorization. It is one of the best optimisation algorithms for this type of minimization problem. This method is simple and powerful, because it guarantees a monotone convergence of stress function.</p>\r\n<p>The coordinates of two-dimensional vectors are recalculated, taking in to consideration not only the coordinates, obtained in the previous iteration, as in classical SMACOF algorithm, but also the new coordinates, obtained in the current iteration. It is mean that Guttman transform matrix is recalculated after each new changed point. Although the algorithm convergence speed increases, but also increases the time cost.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<ul>\r\n<li><strong>Projection space</strong> (int) – low-dimensional space or projection space; positive integer value, space dimension cannot be greater than quantity of attributes in analysed file, default value 2.</li>\r\n<li><strong>Maximum number of iteration</strong>(int) – maximal iteration number, positive integer value, maximum number of iteration must be in interval [1; 1000], default value 100.</li>\r\n<li><strong>Minimal stress change</strong> (double) – Minimal stress change, obtained between two neighboring iterations, must be in interval [10<sup>-8</sup>; ?), default value 0.0001.</li>\r\n<li><strong>Does apply Seidel modification</strong> (boolen) – if the value is equal „True“, it is applied Zeidel modification; by default Zeidel modification is not applied.</li>\r\n</ul>\r\n<h3>DMA | Diagonal majorization algorithm</h3>\r\n<p>The diagonal majorization algorithm (DMA) is modification of SMACOF algorithm. DMA attains a slightly worse MDS projection error than SMACOF, but computing is faster and requires essentially less computing memory. The DMA uses a simpler majorization function. DMA algorithm is used for visualization of large data sets.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<ul>\r\n<li><strong>Projection space</strong> (int) – low-dimensional space or projection space; positive integer value, space dimension cannot be greater than quantity of attributes in analysed file, default value 2.</li>\r\n<li><strong>Maximum number of iteration</strong>(int) – maximal iteration number, positive integer value, maximum number of iteration must be in interval [1; 1000], default value 100.</li>\r\n<li><strong>Minimal stress change</strong> (double) – minimal stress change, obtained between two neighbouring iterations, must be in interval [10<sup>-8</sup>; ?), default value 0.0001.</li>\r\n<li><strong>Relative number of neighbours</strong> (int) – relative number of neighbours, must be in interval (0; 100] %, default value is 1.</li>\r\n</ul>\r\n<h3>Relative MDS | The relative multidimensional scaling algorithm</h3>\r\n<p>The classical MDS is a topology preserving mapping, but it does not offer a possibility to project new points on the existing set of mapped points. To get a mapping that presents the previously mapped points together with the new ones requires a complete re-run of the MDS algorithm on the new and the old data points. Relative MDS is used for visualization of new data points on the fixed mapping and for the visualization of large data sets</p>\r\n<p>The relative MDS algorithm gives precise mapping and saves much computing time as compared with the standard MDS algorithm when is visualized large data sets. Therefore, in the case of limited computing time, the projection by the relative MDS algorithm will be better than that by the standard MDS algorithm.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<ul>\r\n<li><strong>Projection space</strong> (int) – low-dimensional space or projection space; positive integer value, space dimension cannot be greater than quantity of attributes in analysed file, default value 2.</li>\r\n<li><strong>Maximum number of iteration</strong>(int) – maximal iteration number, positive integer value, maximum number of iteration must be in interval [1; 1000], default value 100.</li>\r\n<li><strong>Minimal stress change</strong> (double) – minimal stress change, obtained between two neighbouring iterations, must be in interval [10<sup>-8</sup>; ?), default value 0.0001.</li>\r\n<li><strong>Relative number of basis objects</strong> (int) – Relative basis object quantity must be in interval (0; 100] %.</li>\r\n<li><strong>Select Basis objects strategy</strong> (int) – the strategies of selecting the basis vectors: Random, By line based on PCA, By line based on max variable. Default value is "random".</li>\r\n</ul>\r\n<p> </p>\r\n<h3>SAMANN | SAMANN algorithm</h3>\r\n<p>SAMANN – an unsupervised backpropagation algorithm to train a multilayer feed-forward neural network (SAMANN) to perform the Sammon''s nonlinear projection. A well-known procedure for mapping data from a high-dimensional space onto a lower-dimensional one is Sammon''s mapping. This algorithm preserves as well as possible all interpattern distances.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<ul>\r\n<li><strong>Projection space</strong> (int) – low-dimensional space or projection space; positive integer value, space dimension cannot be greater than quantity of attributes in analysed file, default value 2.</li>\r\n<li><strong>Maximum number of iteration</strong>(int) – maximal iteration number, positive integer value, maximum number of iteration must be in interval [1; 1000], default value 100.</li>\r\n<li><strong>Relative size of the training data </strong>(int) – <strong>Relative size of the training data</strong> of initial data set for SAMANN neural network; relative size of the training data must be in interval (0; 100] %, default value is 10.</li>\r\n</ul>\r\n<ul>\r\n<li><strong>Number of neurons in the hidden layer</strong>(int) – Number of neurons in the hidden layer of the SAMANN neural network, default value is 10.</li>\r\n<li><strong>Value of the learning rate</strong> (double) – Value of the learning ratemust be in interval [0,1;10], default value is 1.</li>\r\n</ul>\r\n<h3>SOM-MDS | Consequent combination of the self-organizing map (SOM) with multidimensional scaling</h3>\r\n<p>The self-organizing map (SOM) is used for both clustering and visualization of multidimensional data, i.e. mapping data from a high-dimensional space onto a lower-dimensional one. The map preserves topological properties of the input space, such that the cells that are close in the map include data instances that are similar to each other.</p>\r\n<p>The main reason of the combination SOM-MDS is to improve the visualization of SOM. Moreover, such a combination allows to decrease the computation time of visualization as compared with alone MDS, when size of analyzed data setis large. At first, all multidimensional data pointsare processed using SOM, then the obtained reference vectors of the winning neurons are displayed, using one of the MDS methods. Usually, the total numberof winning neurons is smaller than number of analysed data instances.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<ul>\r\n<li><strong>Number of rows of SOM</strong> (int) – Number of rows of self-organizing map, SOM rows  quantity must be in interval [3; 100], default value is 10.</li>\r\n<li><strong>Number of columns of SOM</strong> (int) – Number of colums of self-organizing map, SOM colums  quantity must be in interval [3; 100], default value is 10.</li>\r\n<li><strong>Number of SOM training epochs</strong> (int) –Number of SOM training epochs must be in interval [1; 1000], default value is 100.</li>\r\n<li><strong>Projection space of MDS</strong> (int) - low-dimensional space or projection space; positive integer value, space dimension cannot be greater than quantity of attributes in analysed file, default value 2.</li>\r\n<li><strong>Number of iterations of MDS</strong> (int) - maximal iteration number, positive integer value, maximum number of iteration must be in interval [1; 1000], default value 100.</li>\r\n<li><strong>Minimal stress change </strong>(double) – minimal stress change, obtained between two neighbouring iterations, must be in interval [10<sup>-8</sup>; ?), default value 0.0001.</li>\r\n</ul>\r\n<p> </p>\r\n<h2>Data analysis: Classification, clustering</h2>\r\n<h3>SOM | Self-organizing map (SOM)</h3>\r\n<p>The self-organizing map (SOM) is used for both clustering and visualization of multidimensional data, i.e. mapping data from a high-dimensional space onto a lower-dimensional one. The map preserves topological properties of the input space, such that the cells that are close in the map include data instances that are similar to each other.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<ul>\r\n<li><strong>Number of rows </strong> (int) – Number of rows of self-organizing map, SOM rows  quantity must be in interval [3; 100], default value is 10.</li>\r\n<li><strong>Number of columns </strong> (int) – Number of colums of self-organizing map, SOM colums  quantity must be in interval [3; 100], default value is 10.</li>\r\n<li><strong>Number of training epochs</strong> (int) –Number of SOM training epochs must be in interval [1; 1000], default value is 100.</li>\r\n</ul>\r\n<h4>MLP | <strong>Multilayer perceptron</strong></h4>\r\n<p>A <strong>multilayer perceptron</strong> (MLP) is a classifier, a feed forward artificial neural network model that maps sets of input data onto a set of appropriate outputs. A MLP consists of multiple layers of nodes in a directed graph, with each layer fully connected to the next one. Except for the input nodes, each node is a neuron (or processing element) with a nonlinear activation function. MLP utilizes a supervised learning technique called back-propagation for training the network.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<ul>\r\n<li><strong>Maximum number of iteration </strong>(int) – Maximum number of iteration must be in interval [1; 1000], default value is 100.</li>\r\n<li><strong>Number of neurons </strong><strong>in the hidden layer</strong><strong>(1st layer | 2nd layer)</strong> – Number of neurons in the hidden layers: at layer 1 must be greater than 0, at layer 2  cannot be negative.</li>\r\n<li><strong>Size of training data - </strong>the percentage size of the training set. This value should be greater than or equal to 1, default value is 90 %.</li>\r\n<li><strong>Size of validation data -</strong>Size of test data is calculated automatically, by formula (100 % - Size of training data), default value is 10 %.</li>\r\n<li><strong>Number of folds for cross-validation</strong> (int) - Number of folds for cross-validation</li>\r\n</ul>\r\n<p> </p>\r\n<h4>RDF | Random decision forest</h4>\r\n<p>The RDF algorithm is a modification of the original Random Forest algorithm designed by Leo Breiman and Adele Cutler. Two ideas are in combination with each other in this algorithm: these are the use of a decision tree committee getting the result by voting, and the idea of training process randomization.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<ul>\r\n<li><strong>Pasikliovimo lygmuo</strong> (double) – pasikliovimo lygmuo, įvertinant klaidos tikimybės pasikliautinąjį intervalą.</li>\r\n<li><strong>Mokymo aibės dydis</strong> (int) – mokymo objektų skaičius.</li>\r\n<li><strong>Testavimo aibės dydis</strong> (int) – testavimo objektų skaičius.</li>\r\n</ul>\r\n<h4>K-means | k-means clustering</h4>\r\n<p>k-means clustering aims to partition the points into <em>k</em> groups such that the sum of squares from points to the assigned cluster centres is minimized. At the minimum, all cluster centres are at the mean of their Voronoi sets (the set of data points which are nearest to the cluster centre).</p>\r\n<p><strong>Parameters:</strong></p>\r\n<ul>\r\n<li><strong>Maximum number of iteration (int) </strong>– Number of iteration must be in interval [1; 1000], default valu eis 100.</li>\r\n<li><strong>Maximum number of cluster (int)</strong>– Number of cluster must be in interval [1; 100], default value is 10.</li>\r\n</ul>\r\n<p> </p>\r\n<h2>View results</h2>\r\n<h3>Technical details</h3>\r\n<p>the component "Technical details" is used to view for technical information: computation time, report about errors and so on. You can view the obtained results after the experiment execution.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<p>This component does not have control parameters.</p>\r\n<h3>Matrix view</h3>\r\n<p>Matrix view component is used to view upload data, obtained results of experiments (in table form). Matrix view component is connected to the upload file component or with the component of selected algorithm.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<p>This component does not have control parameters.</p>\r\n<h3>Chart view</h3>\r\n<p>Chart view component is used to view scatterplot of the obtained results. This component is connected with component of selected data mining algorithm. The user can view the obtained results after the experiment execution.</p>\r\n<p><strong>Parameters:</strong></p>\r\n<p>This component does not have control parameters.</p>', 5, '2014-06-02 16:44:40', '2014-06-05 14:01:06', 'en'),
    (2, 'FAQ', 'faq', 'help', '<div class="offset1 span9">\r\n<h2>Frequently Asked Questions</h2>\r\n<p><strong>What is DAMIS?</strong></p>\r\n<p>DAMIS – Web Service Based Data Mining Tool for Multidimensional Data Analysis. DAMIS is a pilot user-friendly Web-based solution for planning and executing data mining experiments in remote multi-core computational clusters. It is a scientist''s tool, including a collection of ready-to-use research-based data mining algorithms, data upload and storing services, data retrieval from the MIDAS e-Infrastructure, a visual experiment work-flow editor and results visualization tools.</p>\r\n<p><strong>What methods of data analysis are available in DAMIS tool? <br /></strong></p>\r\n<p>It is possible to use these methods of data analysis in DAMIS tool:</p>\r\n<ul>\r\n<li>Principal component analysis (PCA);</li>\r\n<li>Multidimensional scaling (MDS) SMACOF algorithm;</li>\r\n<li>Zeilel’s modification of MDS SMACOF;</li>\r\n<li>Diagonal majorization algorithm (DMA);</li>\r\n<li>Relative multidimensional scaling algorithm;</li>\r\n<li>SAMANN – an unsupervised backpropagation algorithm to train a multilayer feed-forward neural network (SAMANN) to perform the Sammon''s nonlinear projection;</li>\r\n<li>Self-organizing map (SOM);</li>\r\n<li>Consequent combination of the self-organizing map (SOM) with multidimensional scaling;</li>\r\n<li>A multilayer perceptron (MLP) - a classifier, a feed forward artificial neural network model that maps sets of input data onto a set of appropriate outputs;</li>\r\n<li>Random decision forest classifier;</li>\r\n<li>K-means algorithm for clustering.</li>\r\n</ul>\r\n<h4>How to use uploaded data file in experiment workflow?</h4>\r\n<p>Component "EXISTING DATA" is used for this purpose. Firstly you have to drag this component to the experiment workflow, double click on it and choose your uploaded file from dropdown menu. Now you can construct rest of your experiment.</p>\r\n<h4>How to see experiment results after experiment execution?</h4>\r\n<p>You have to join one of "VIEW RESULTS" component to the ending of your experiment workflow. When experiment finishes its execution "VIEW RESULTS" components become active, if you double click on them results will be displayed.</p>\r\n<p><strong>What formats of supported file can we upload on DAMIS?</strong></p>\r\n<p>It is possible to upload data table from a supported file formats: tab, txt, csv, ARFF and XML files, which are compressed in zip format.</p>\r\n<p>Requirements for data file: A dataset is roughly equivalent to a two-dimensional spreadsheet or database table. A dataset is a collection of instances, where each instance consists of a number of attributes. The external representation of an instances class is an ARFF file, which consists of a header describing the attribute types and the data as comma-separated list.</p>\r\n<p>Also, the user has the possibility to edit or delete already uploaded files. Selecting the file management tab is displayed the list of uploaded data files: names and sizes of stored files. The list of uploaded data files can be sorted according to the names of data files and the date of upload. A user can download to his computer uploaded files and the results files, obtained after the experiment execution, in the following formats: arff, zip, tab, csv, xls, xlsx.</p>\r\n<p><strong>Why to use ARFF file format of analysed data for the work with the DAMIS tool is better? How to describe the upload data?</strong></p>\r\n<p>In order to avoid errors and other inconveniences, it is advisable to choose the ARFF file format. An ARFF (Attribute-Relation File Format) file is an ASCII text file that describes a list of instances sharing a set of attributes.</p>\r\n<p>ARFF files have two distinct sections: the Header information and the Data information.</p>\r\n<p>The Header of the ARFF file contains the name of the relation (@RELATION), a list of the attributes (@ATTRIBUTE) (the columns in the data), and their types (NUMERIC (real or integer), STRING, DATE). Lines that begin with a % are comments. The @RELATION, @ATTRIBUTE and @DATA declarations are case insensitive.</p>\r\n<p>An example header on the standard IRIS dataset looks like this: </p>\r\n<pre>@RELATION iris\r\n\r\n   @ATTRIBUTE sepallength  NUMERIC\r\n   @ATTRIBUTE sepalwidth   NUMERIC\r\n   @ATTRIBUTE petallength  NUMERIC\r\n   @ATTRIBUTE petalwidth   NUMERIC\r\n   @ATTRIBUTE class        {Iris-setosa,Iris-versicolor,Iris-virginica}</pre>\r\n<p>The Data of the ARFF file looks like the following:</p>\r\n<pre>@DATA\r\n   5.1,3.5,1.4,0.2,Iris-setosa\r\n   4.9,3.0,1.4,0.2,Iris-setosa\r\n   4.7,3.2,1.3,0.2,Iris-setosa\r\n   4.6,3.1,1.5,0.2,Iris-setosa\r\n   5.0,3.6,1.4,0.2,Iris-setosa</pre>\r\n<p>Missing values are represented by a single question mark, as in: </p>\r\n<pre> @DATA\r\n   ?,3.5,?,0.2,Iris-setosa</pre>\r\n<p><strong>How do I view the results of my experiments?</strong></p>\r\n<p>For viewing of the obtained results you can use three components:</p>\r\n<ul>\r\n<li><strong>“Technical details” - </strong>the componentis used to view for technical information: computation time, report about errors and so on. You can view the obtained results after the experiment execution. This component is connected with component of selected data mining algorithm.</li>\r\n<li><strong>“Matrix view” </strong>- Matrix view component is used to view upload data, obtained results of experiments (in table form). Matrix view component is connected to the upload file component or component of selected algorithm.</li>\r\n<li><strong>“Chart view” – </strong>Chart view component is used to view scatterplot of the obtained results. This component is connected with component of selected data mining algorithm. You can view the obtained results after the experiment execution.</li>\r\n</ul>\r\n<p>User can double click on the one of these component and view obtained results of experiment. Also, user can download the obtained results to his computer using <strong>Technical detail</strong> or <strong>Matrix view</strong> component.</p>\r\n<p><strong>How can user perform an experiment on DAMIS with </strong><strong>own</strong><strong> data set?</strong></p>\r\n<p>The experiment planning and execution environment is available to an authenticated user. The user can compose experiments by dragging algorithms from the tool on the left to the working area, providing parameters by double clicking the corresponding icon and filling in the parameters form and connecting the icons.</p>\r\n<p>The user drags the <strong>Upload new file</strong> component to the working area and double clicks it to select his dataset. Then, the user chooses all necessary components from tool and connects them step by step, according the plan of his experiment. Finally, the user chooses to view the obtained result using one of <strong>View results</strong> components, which gives a representation of the algorithm results. The user clicks the <strong>Execute</strong> button when he finishes editing. A work-flow is validated, analyzed and remote services, corresponding to each of the algorithms, are called. The results are available by double clicking the <strong>View result</strong> component.</p>\r\n<p>If it is found an error in the sequence, an error message appears above the component, in which the error is occurred, or the component, in which the control parameters is entered incorrectly, is colored in red.</p>\r\n<p><strong>How to know if the results of my experiment are already formed?</strong></p>\r\n<p>When the user finishes editing his experiments workflow, save it with new name and clicks the <strong>Execute</strong> button on the bottom of workflow, this new experiment appears in the list of experiments history in tab EXPERIMENTS. The new experiment is gaining the status of "Executing”. When new experiment is gaining the status of “Finished”, the obtained results will be available for viewing.</p>\r\n<p><strong>Can the user analyse a data file with missing values using DAMIS tool?</strong></p>\r\n<p>The user drags the Upload new file component to the working area and double clicks it to select his dataset. If the analysed data set has missing values, it is necessary to clean data using cleaning data component. The user drags the Clean data component to the working area and connects it with the Upload new file component. At the moment if missing object data is found, then this object will be eliminated from the further calculations. In this way it is ensured that all data records will have values and are suitable for further analysis.</p>\r\n<p><strong>How to recover a forgotten Password of DAMIS account?</strong></p>\r\n<p>It is possible to reset your password. From the LOGIN tab click link <strong>Forgot password? </strong></p>\r\n<p>Enter the email address you used to create the account and an email will be sent with a link you can use to reset your password.</p>\r\n<p><strong>I would like to know the running time of the algorithm</strong><strong>after experiment execution. How to do it?</strong></p>\r\n<p><strong>“Technical details” - </strong>the componentis used to view for technical information: computation time, report about errors and so on. You can view the obtained results after the experiment execution. This component is connected with component of selected data mining algorithm.</p>\r\n</div>', 2, '2014-03-17 16:22:46', '2014-06-06 08:46:47', 'en'),
    (3, 'Vartotojo instrukcija', 'vartotojo-instrukcija', 'help', '<p><iframe src="../../../docs/help_lt.htm" width="100%" height="780" frameborder="0"></iframe></p>\r\n<p>Išsami pagalba lietuvių kalba:  <a href="../../../docs/Vartotojo_instrukcija.pdf">pdf</a>.</p>', 3, '2014-03-17 17:00:54', '2015-02-11 18:12:19', 'lt'),
    (4, 'DUK', 'duk', 'help', '<div class="offset1 span9">\r\n<h2>Dažnai užduodami klausimai</h2>\r\n<h4>Kas yra DAMIS?</h4>\r\n<p>DAMIS (duomenų analizės įrankis) – tai atvira mokslo infrastruktūra, skirta duomenų analizei atlikti. Įrankio paskirtis – sudaryti galimybę atlikti pagrindinius duomenų analizės tyrimus (grupavimą, klasifikavimą ir kt.); vizualios analizės priemonėmis tirti daugiamačių duomenų projekcijas į plokštumą, duomenų grupavimąsi, duomenų panašumus, atskirų daugiamačių duomenų požymių įtaką ir tarpusavio priklausomybes; stebėti bei apdoroti vizualizacijos ar našiųjų skaičiavimų aplinkoje gautus tyrimų rezultatus.</p>\r\n<h4>Kokie duomenų analizės metodai yra prieinami DAMIS įrankyje?</h4>\r\nDAMIS įrankyje šiuo metu yra prieinami šie duomenų analizės metodai:\r\n<ul>\r\n<li>Pagrindinių komponenčių analizės (PCA) algoritmas.</li>\r\n<li>Daugiamačių skalių grupei (MDS) priklausantis klasikinis SMACOF algoritmas.</li>\r\n<li>SMACOF algoritmo Zeidelio modifikacija (SMACOF (MDS)).</li>\r\n<li>Diagonalinis mažoravimo algoritmas (DMA).</li>\r\n<li>Santykinės daugiamatės skalės (Relative MDS).</li>\r\n<li>Dirbtiniais neuroniniais tinklais ir daugiamatėmis skalėmis grindžiamas SAMANN algoritmas.</li>\r\n<li>Saviorganizuojančiais neuroniniais tinklais (SOM) grindžiamas algoritmas.</li>\r\n<li>MDS ir SOM junginys (SOM-MDS).</li>\r\n<li>Daugiasluoksnis perceptronas (MLP) grindžiamas klaidos sklidimo atgal taisykle.</li>\r\n<li>Atsitiktinių miškų (RDF) klasifikatorius</li>\r\n<li>K-vidurkių (K-means) algoritmas.</li>\r\n</ul>\r\n<h4>Kaip eksperimente panaudoti prieš tai įkeltą duomenų failą?</h4>\r\n<p>Eksperimento metu norint panaudoti prieš tai įkeltą duomenų failą prie eksperimento darbų sekos reikia prijungti komponentę  "Pasirinkti įkeltą failą".</p>\r\n<h4>Kokiais formatais turi būti pateikiami sistemai duomenis?</h4>\r\n<p>DAMIS įrankiui duomenys gali būti pateikiami šiais formatais: arff, tab, txt, csv, XML, xls, zip. Taip pat naudotojas turi galimybę redaguoti arba ištrinti jau įkeltus failus. Pasirinkus failų valdymo skiltį yra rodomas jau įkeltų duomenų failų sąrašas, kuriame pateiktas kiekvieno saugomo failo pavadinimas ir dydis. Failų sąrašą galima rūšiuoti pagal duomenų failų pavadinimus, įkėlimo datą. Įkeltus ir gautus rezultatų failus po darbų sekų įvykdymo naudotojas gali atsiųsti į savo kompiuterį arba patalpinti MIDAS archyve šiais formatai: arff, zip, tab, csv, xls, xlsx.</p>\r\n<h4>Kodėl darbui su DAMIS įrankiu geriau pasirinkti ARFF formato failą ir kaip geriau aprašyti duomenis?</h4>\r\n<p>Norint išvengti klaidų ir kitų nepatogumų, patartina pasirinkti ARFF formato failą. ARFF (Attribute-Relation File Format) failas – ASCII tekstinis failas, kuriame objektai, sudarantys konkrečią analizuojamų objektų aibę, yra apibūdinami bendrais požymiais. ARFF failas sudarytas iš dviejų dalių: antraštė ir duomenys.</p>\r\n<p>ARFF failo antraštę sudaro: informacija apie duomenų aibės pavadinimą (@RELATION), požymių sąrašas (@ATTRIBUTE) ir jų tipai (NUMERIC (real arba integer), STRING, DATA, &lt;galimų_reikšmių_aibė&gt;):</p>\r\n<pre>   @RELATION iris\r\n\r\n   @ATTRIBUTE sepallength  NUMERIC\r\n   @ATTRIBUTE sepalwidth   NUMERIC\r\n   @ATTRIBUTE petallength  NUMERIC\r\n   @ATTRIBUTE petalwidth   NUMERIC\r\n   @ATTRIBUTE class        {Iris-setosa,Iris-versicolor,Iris-virginica}</pre>\r\n<p>ARFF failo duomenys aprašomi, kaip pavaizduota pavyzdyje:</p>\r\n<pre>   @DATA\r\n   5.1,3.5,1.4,0.2,Iris-setosa\r\n   4.9,3.0,1.4,0.2,Iris-setosa\r\n   4.7,3.2,1.3,0.2,Iris-setosa\r\n   4.6,3.1,1.5,0.2,Iris-setosa\r\n   5.0,3.6,1.4,0.2,Iris-setosa</pre>\r\n<p>Trūkstamos reikmės keičiamos klaustuko ženklu "?":</p>\r\n<pre>   @DATA\r\n   ?,3.5,?,0.2,Iris-setosa</pre>\r\n<h4>Kaip peržiūrėti eksperimentų rezultatus?</h4>\r\n<p>Norint peržiūrėti gautus eksperimentų rezultatus, į eksperimento užduočių seką reikia įkelti vieną iš trijų komponenčių:  </p>\r\n<ul>\r\n<li>„Techninė informacija“ – tai komponentė, skirta techninei informacijai peržiūrėti: skaičiavimo laikui, gautos paklaidos ir kt.</li>\r\n<li>„Matricinis vaizdavimas“ – tai komponentė, kurios pagalba naudotojas galės peržiūrėti duomenis ar algoritmų rezultatus matricos (lentelės) pavidalu, kai ši komponentė bus sujungta su failo įkėlimo ar algoritmo komponente.</li>\r\n<li>„Grafinis vaizdavimas“ – tai komponentė, kurios pagalba naudotojas galės peržiūrėti rezultatų grafiką, sujungus su vykdyto algoritmo komponente ir spragtelėjus ją du kartus. Atsidariusiame grafike naudotojas galės matyti grafiką.</li>\r\n</ul>\r\n<p>Naudotojas rezultatų peržiūros komponentes galės naudoti tik tuomet, kai bus apskaičiuoti eksperimento rezultatai.</p>\r\n<p>Komponentės „Grafinis vaizdavimas“ ir „Matricinis vaizdavimas“ turi galimybę atsiųsti rezultatus.</p>\r\n<h4>Kaip atlikti eksperimentą?</h4>\r\n<p>Norint atlikti eksperimentą su norima duomenų aibe, reikia sukurti norimą darbų seką ir ją įvykdyti. Tam reikia nutempti į eksperimento planavimo darbalaukį norimas komponentes, užpildyti reikiamų valdymo parametrų reikšmes, sujungti reikiamas komponentes ir paspausti mygtuką „vykdyti“. Tuomet atidaromas eksperimento vykdymo parametrų užpildymo langas. Užpildžius reikiamus laukus ir paspaudus mygtuką „Patvirtinti“, vyksta sekos patikrinimas: tikrinami kiekvienos komponentės įvesti valdymo parametrai ir kiekvienos komponentės sujungimas. Jei sekoje rastos klaidos, rodomas klaidos pranešimas prie nesujungtos komponentės arba pažymima raudonai ta komponentė, kurioje neteisingai įvesti valdymo parametrai. Priešingu atveju, jei komponentės sujungtos teisingai ir valdymo parametrai užpildyti tinkamai, tuomet eksperimentų istorijoje atsiranda naujas eksperimentas, kurio statusas „Vykdomas“.</p>\r\n<h4>Kaip sužinoti ar jau suformuoti eksperimento rezultatai?</h4>\r\n<p>Eksperimento planavimo lange sukūrus norimą darbų seką ir paspaudus mygtuką „Vykdyti“, eksperimentų istorijoje atsiranda naujas eksperimentas su nauju pavadinimu ir statusu „Vykdomas“. Kai eksperimentas įgauna statusą „Įvykdytas“, eksperimentų rezultatai bus prieinami peržiūrai.</p>\r\n<h4>Ar naudojantis DAMIS įrankiu galima analizuoti duomenų failą, kuriame yra praleistų reikšmių?</h4>\r\n<p>Jeigu duomenų failas turi praleistų reikšmių, tai norint jį analizuoti dimensijos mažinimo, klasifikavimo arba grupavimo metodais, duomenys turi būti išvalyti, prie duomenų įkėlimo komponentės prijungus  komponentę „Valymas“.</p>\r\n<h4>Pamiršau prisijungimo slaptažodį. Ką man daryti?</h4>\r\n<p>Pamiršus slaptažodį jį galima atstatyti. Prisijungimo lange paspauskite nuorodą „Pamiršau slaptažodį“, įveskite el. pašto adresą, kuriuo registravotės, ir sekite tolimesnius nurodymus.</p>\r\n<h4>Sėkmingai įvykdžius eksperimentą, noriu sužinoti algoritmo veikimo laiką. Kaip tai padaryti?</h4>\r\n<p>DAMIS yra realizuota galimybė peržiūrėti duomenų analizės algoritmo veikimo technines charakteristikas: veikimo laiką, gautą paklaidą ir kitas charakteristikas. Norint pamatyti šią informaciją prie duomenų analizės komponentės reikia prijungti komponentę „Techninė informacija“, esančią rezultatų peržiūros dalyje.</p>\r\n<p> </p>\r\n</div>', 4, '2014-03-18 09:30:03', '2014-10-16 18:59:24', 'lt'),
    (5, 'Pradinis puslapis', 'pradinis-puslapis', 'front_page', '<p><strong>DAMIS</strong> – tai duomenų analizės įrankis, sudarantis tyrėjams galimybę atlikti pagrindinius duomenų analizės tyrimus (klasifikavimą ir grupavimą), vizualios analizės priemonėmis tirti daugiamačių duomenų projekcijas į plokštumą, duomenų tarpusavio panašumus, atskirų daugiamačių duomenų požymių įtaką ir tarpusavio priklausomybes, naudojant lygiagrečiųjų ir paskirstytųjų skaičiavimo išteklius (VU MII klasteris – VU MIF superkompiuteris). Taip pat yra įgyvendinti pradinio duomenų apdorojimo bei pagrindinių statistinių charakteristikų apskaičiavimo algoritmai. Tyrėjas, sudarydamas mokslinių darbų sekas, gali nurodyti, kokia tvarka bus vykdomi duomenų apdorojimo ir analizės algoritmai. Yra galimybė sudarytas sekas keisti, išsaugoti, naudoti kitų duomenų analizei. Gautus rezultatus galima išsaugoti naudotojo kompiuteryje arba MIDAS saugykloje.</p>\r\n<p>Įrankis sukurtas pagal 2013 m. vasario 12 d. duomenų analizės metodų algoritmizavimo ir pilotinio įrankio programinės įrangos sukūrimo paslaugų sutartį Nr. APS-580000-243 tarp VšĮ „Informatikos mokslų centras“ ir Vilniaus universiteto. Paslauga vykdoma Vilniaus universitetui įgyvendinant Europos regioninės plėtros fondo remiamą projektą „Nacionalinės atviros prieigos mokslo informacijos duomenų archyvas“ pagal „Informacinė visuomenė visiems“ prioriteto įgyvendinimo priemonę Nr. VP2-3.1-IVPK-13-V „Mokslo duomenų archyvas“.</p>\r\n<p><strong>DAMIS kūrėjas</strong> – Všį „Informatikos mokslų centras“ <a href="http://www.inscience.lt">http://www.inscience.lt</a>.</p>\r\n<p>Išeities kodas – <a href="https://github.com/InScience/DAMIS">https://github.com/InScience/DAMIS</a> ir <a href="https://github.com/InScience/DAMIS-GUI">https://github.com/InScience/DAMIS-GUI</a>.</p>\r\n<p>Pastebėjote klaidas ar netikslumus, <strong>susisiekite su mums</strong>: <a href="mailto:info@inscience.lt">info@inscience.lt</a></p>', 1, '2014-04-29 13:22:16', '2014-10-31 07:31:06', 'lt'),
    (6, 'Front page', 'front-page', 'front_page', '<p><strong>DAMIS</strong> is a tool for data analysis, allowing researchers to carry out the basic data analysis (clustering and classification) and to investigate multidimensional data projection on a plane, the similarities between the data items, the influence of individual features and their relationships by visual analysis techniques, using the high performance computing resources (VU MII cluster – VU MIF supercomputer). The algorithms for the data pre-processing and calculation of the main statistical characteristics are also implemented. Using scientific workflows, a researcher can specify the order in which the data processing and analysis algorithms should be executed. There is a possibility to change and save the workflows composed, as well as to use them for the analysis of other data. The results obtained can be saved to a user’s computer and MIDAS repository.</p>\r\n<p><strong>DAMIS developer</strong> is a public institution “Informatikos mokslų centras” <a href="http://www.inscience.lt">http://www.inscience.lt</a>.</p>\r\n<p><strong>Source code</strong> is available on <a href="https://github.com/InScience/DAMIS">https://github.com/InScience/DAMIS</a> and <a href="https://github.com/InScience/DAMIS-GUI">https://github.com/InScience/DAMIS-GUI</a></p>\r\n<p>Have you noticed any errors or omissions? P<strong>lease contact us</strong>: <a href="mailto:info@inscience.lt">info@inscience.lt</a></p>', 2, '2014-04-29 13:24:36', '2014-10-31 07:31:33', 'en');

-- ---------------------------------------------------------
-- Demo user (demo demo and admin admin)
-- ---------------------------------------------------------

INSERT INTO `users` (`id`, `username`, `username_canonical`, `email`, `email_canonical`, `enabled`, `salt`, `password`, `last_login`, `locked`, `expired`, `expires_at`, `confirmation_token`, `password_requested_at`, `roles`, `credentials_expired`, `credentials_expire_at`, `registeredAt`, `name`, `surname`, `organisation`, `user_id`) VALUES
    (1, 'demo', 'demo', 'demo@inscience.lt', 'demo@demo.lt', 1, '1vaf1uutuem8sk0w0gkgkgk4gwcgs0w', 'zod1RG6+fnCRNkzETBzRevAPdQOdXTjnkBQGYIvLMoi7jsudRmUBRfOInLiCoHYJSeooQ5ZUbeSdiuGzKplL+A==', '2014-11-13 16:29:58', 0, 0, NULL, NULL, NULL, 'a:1:{i:0;s:14:"ROLE_CONFIRMED";}', 0, NULL, '2014-04-02 11:16:08', NULL, NULL, NULL, NULL),
    (2, 'admin', 'admin', 'info@inscience.lt', 'admin@demo.lt', 1, 'r44z0x3uuas4g4ok8w0kc8w0k800wg4', 'ShzAgl/XCGIcUXGWmC5NFJExCeMy4PVzbHxNbkG89wHxnLhToBzEW1if5TTeZifs4II3YFp+4pS/UX4eIQnVHw==', '2014-11-13 16:30:11', 0, 0, NULL, NULL, NULL, 'a:2:{i:0;s:14:"ROLE_CONFIRMED";i:1;s:10:"ROLE_ADMIN";}', 0, NULL, '2014-11-13 16:27:01', 'Admin', 'Admin', 'Organization', NULL);

SET FOREIGN_KEY_CHECKS = 1;