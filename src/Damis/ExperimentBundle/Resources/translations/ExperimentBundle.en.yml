Maximum number of cluster: Number of clusters
Upload file for data analysis : Upload data file. It is possible to upload data table from a supported file formats: tab, txt, csv, ARFF and XML files, which are compressed in zip format.  A dataset is roughly equivalent to a two-dimensional spreadsheet or database table.
Select uploaded file : Open a set of instances from DAMIS data base.
Select file from MIDAS archive : Open a set of instances from MIDAS data base. It is possible to upload data table from a supported file formats: tab, txt, csv, ARFF and XML files, which are compressed in zip format.  A dataset is roughly equivalent to a two-dimensional spreadsheet or database table.
Data cleaning : Cleaning data reduces errors and improves the data quality for further data analysis. After reading the ARFF file, data section checking is initiated. Each data section attribute is checked whether its data type conforms the type declared in attribute section if not then error message is sent to the user. Also it is removed records with missing values.
Filter data: Filtering removes instances from dataset that meet a particular criterion. These instances are called outliers, i.e.the data instances which are significantly different from the remaining data. Result of filtering should be either the analyzed data set without outliers, or only outliers.
Split a file into given number of parts : Split data – splitting of initial data set into two smaller subsets. Two obtained subsets could be analysed by parallel or analysed one of them, for example, subset of instances could be represented regularities of all population.
Data transformation : The measurement unit used can affect the data analysis. To help avoid dependence on the choice of measurement units, the data should be normalized or standardized. This involves transforming the data to fall within a smaller or common range. Normalizing the data attempts to give all attributes an equal weight. 
Select features :Feature selection component is used to manually compose new analyzed data domain. It is possible to decide which attributes will be used and how. For instance, for building a classification model, the domain would be composed of a set of attributes and a class attribute, which is also selected from a set of attributes. The attributes are included in the data set but are, for most of the methods, not considered in data analysis.
The set of statistical primitives : Calculation of statistical primitives for each feature values: min, max, mean, standard deviation, median.
Principal Component Analysis : PCA is a standard technique for visualizing high dimensional data and for data pre-processing. PCA reduces the dimensionality (the number of variables) of a data set by maintaining as much variance as possible.
SMACOF (MDS) algorithm : The multidimensional scaling (MDS) is a group of methods that project multidimensional data to a low (usually two) dimensional space and preserve the interpoint distances among data as much as possible. The goal of multidimensional scaling is to find low-dimensional points, such that the distances between he points in the low-dimensional space were as close to the proximities as possible.
Diagonal majorization algorithm : The diagonal majorization algorithm (DMA) is modification of SMACOF algorithm. DMA attains a slightly worse MDS projection error than SMACOF, but computing is faster and requires essentially less computing memory. The DMA uses a simpler majorization function. DMA algorithm is used for visualization of large data sets.
Relative Multidimensional Scaling (MDS)  algorithm : The classical MDS is a topology preserving mapping, but it does not offer a possibility to project new points on the existing set of mapped points. To get a mapping that presents the previously mapped points together with the new ones requires a complete re-run of the MDS algorithm on the new and the old data points. Relative MDS is used for visualization of new data points on the fixed mapping and for the visualization of large data sets
SAMANN algorithm : SAMANN – an unsupervised backpropagation algorithm to train a multilayer feed-forward neural network (SAMANN) to perform the Sammon's nonlinear projection. A well-known procedure for mapping data from a high-dimensional space onto a lower-dimensional one is Sammon's mapping. This algorithm preserves as well as possible all interpattern distances.
SOM for Multidimensional Data Visualization : The main reason of the combination SOM-MDS is to improve the visualization of SOM. Moreover, such a combination allows to decrease the computation time of visualization as compared with alone MDS, when size of analyzed data setis large. At first, all multidimensional data pointsare processed using SOM, then the obtained reference vectors of the winning neurons are displayed, using one of the MDS methods. Usually, the total numberof winning neurons is smaller than number of analysed data instances.
Self-Organizing Map (SOM) : The self-organizing map (SOM) is used for both clustering and visualization of multidimensional data, i.e. mapping data from a high-dimensional space onto a lower-dimensional one. The map preserves topological properties of the input space, such that the cells that are close in the map include data instances that are similar to each other.
Multilayer perceptron : A multilayer perceptron (MLP) is a classifier, a feed forward artificial neural network model that maps sets of input data onto a set of appropriate outputs. A MLP consists of multiple layers of nodes in a directed graph, with each layer fully connected to the next one. Except for the input nodes, each node is a neuron (or processing element) with a nonlinear activation function. MLP utilizes a supervised learning technique called back-propagation for training the network.
RDF classifier : The RDF algorithm is a modification of the original Random Forest algorithm designed by Leo Breiman and Adele Cutler. Two ideas are in combination with each other in this algorithm: these are the use of a decision tree committee getting the result by voting, and the idea of training process randomization.
k-means clustering : k-means clustering aims to partition the points into k groups such that the sum of squares from points to the assigned cluster centres is minimized. At the minimum, all cluster centres are at the mean of their Voronoi sets (the set of data points which are nearest to the cluster centre).
Show all component's outputs' values : The component "Technical details" is used to view for technical information: computation time, report about errors and so on. You can view the obtained results after the experiment execution.
Results matrix view : Matrix view component is used to view upload data, obtained results of experiments (in table form). Matrix view component is connected to the upload file component or with the component of selected algorithm.
Chart : Chart view component is used to view scatterplot of the obtained results. This component is connected with component of selected data mining algorithm. The user can view the obtained results after the experiment execution.